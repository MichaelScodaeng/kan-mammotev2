{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e349f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Setting up LSTM Time Embedding Comparison...\n",
      "🔧 Using device: cuda\n",
      "✅ Setup complete! All imports and model definitions loaded.\n",
      "✅ Device: cuda\n",
      "✅ Results directory: /home/s2516027/kan-mammote/results\n",
      "🚀 Ready to run the comparison!\n"
     ]
    }
   ],
   "source": [
    "# 🚀 LSTM Time Embedding Comparison - Complete Setup Cell\n",
    "print(\"🔧 Setting up LSTM Time Embedding Comparison...\")\n",
    "\n",
    "# Core imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep learning imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import tqdm # Import tqdm\n",
    "\n",
    "# Add project root to path\n",
    "project_root = '/home/s2516027/kan-mammote'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Import project modules\n",
    "from src.models.kan_mammote import KANMAMMOTE\n",
    "from src.utils.config import KANMAMOTEConfig\n",
    "from src.LETE.LeTE import CombinedLeTE as LeTE # Import CombinedLeTE and alias it as LeTE\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "LSTM_HIDDEN_DIM = 128\n",
    "TIME_EMBEDDING_DIM = 64\n",
    "DROPOUT_RATE = 0.2\n",
    "THRESHOLD = 0.3\n",
    "GRAD_CLIP_NORM = 1.0\n",
    "\n",
    "# Setup device and directories\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🔧 Using device: {device}\")\n",
    "\n",
    "RESULTS_DIR = f\"{project_root}/results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "class EventBasedMNIST(Dataset):\n",
    "    \"\"\"Convert MNIST to event-based representation.\"\"\"\n",
    "    \n",
    "    def __init__(self, root, train=True, threshold=0.3, download=False):\n",
    "        self.threshold = threshold\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        self.mnist = datasets.MNIST(root=root, train=train, download=download, transform=transform)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mnist)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.mnist[idx]\n",
    "        \n",
    "        # Convert to event representation\n",
    "        image = image.squeeze().numpy()\n",
    "        \n",
    "        # Create events for pixels above threshold\n",
    "        events = []\n",
    "        features = []\n",
    "        \n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                if image[i, j] > self.threshold:\n",
    "                    position = i * 28 + j  # Flatten position\n",
    "                    events.append(position)\n",
    "                    features.append(image[i, j])\n",
    "        \n",
    "        if len(events) == 0:\n",
    "            events = [0]\n",
    "            features = [0.0]\n",
    "        \n",
    "        return np.array(events), np.array(features), label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for variable length sequences.\"\"\"\n",
    "    events_batch = []\n",
    "    features_batch = []\n",
    "    lengths = []\n",
    "    labels = []\n",
    "    \n",
    "    max_len = max(len(events) for events, _, _ in batch)\n",
    "    \n",
    "    for events, features, label in batch:\n",
    "        length = len(events)\n",
    "        lengths.append(length)\n",
    "        labels.append(label)\n",
    "        \n",
    "        # Pad sequences\n",
    "        padded_events = np.zeros(max_len, dtype=np.int64)\n",
    "        padded_features = np.zeros(max_len, dtype=np.float32)\n",
    "        \n",
    "        padded_events[:length] = events\n",
    "        padded_features[:length] = features\n",
    "        \n",
    "        events_batch.append(padded_events)\n",
    "        features_batch.append(padded_features)\n",
    "    \n",
    "    return (torch.tensor(events_batch), \n",
    "            torch.tensor(features_batch), \n",
    "            torch.tensor(lengths), \n",
    "            torch.tensor(labels))\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count trainable parameters in a model.\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "class TrueBaselineLSTM(nn.Module):\n",
    "    \"\"\"True baseline LSTM without any time embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=784, hidden_dim=128, num_classes=10, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Just use feature values directly\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=1,  # Just the pixel values\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, events, features, lengths):\n",
    "        if features.size(0) == 0:\n",
    "            return torch.zeros(0, 10, device=features.device)\n",
    "        \n",
    "        lengths = torch.clamp(lengths, min=1, max=features.size(1))\n",
    "        \n",
    "        # Use only pixel values, no positional information\n",
    "        x = features.unsqueeze(-1)  # Add feature dimension\n",
    "        \n",
    "        # Pack sequences\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        # Classify using last hidden state\n",
    "        output = self.classifier(h_n[-1])\n",
    "        return output\n",
    "\n",
    "class LearnablePositionLSTM(nn.Module):\n",
    "    \"\"\"LSTM with learnable position embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=784, hidden_dim=128, num_classes=10, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        # Learnable position embedding\n",
    "        self.position_embedding = nn.Embedding(input_size, TIME_EMBEDDING_DIM)\n",
    "        \n",
    "        # Feature projection\n",
    "        self.feature_proj = nn.Linear(1, TIME_EMBEDDING_DIM)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=TIME_EMBEDDING_DIM,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, events, features, lengths):\n",
    "        if events.size(0) == 0:\n",
    "            return torch.zeros(0, 10, device=events.device)\n",
    "        \n",
    "        lengths = torch.clamp(lengths, min=1, max=events.size(1))\n",
    "        \n",
    "        # Get position embeddings\n",
    "        pos_emb = self.position_embedding(events)\n",
    "        \n",
    "        # Project features\n",
    "        feat_emb = self.feature_proj(features.unsqueeze(-1))\n",
    "        \n",
    "        # Combine position and feature embeddings\n",
    "        combined = pos_emb + feat_emb\n",
    "        \n",
    "        # Pack sequences\n",
    "        packed = pack_padded_sequence(combined, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        # Classify\n",
    "        output = self.classifier(h_n[-1])\n",
    "        return output\n",
    "\n",
    "class SinCosLSTM(nn.Module):\n",
    "    \"\"\"LSTM with sinusoidal position embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=784, hidden_dim=128, num_classes=10, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Feature projection\n",
    "        self.feature_proj = nn.Linear(1, TIME_EMBEDDING_DIM)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=TIME_EMBEDDING_DIM,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def get_sincos_embeddings(self, positions):\n",
    "        \"\"\"Generate sinusoidal position embeddings.\"\"\"\n",
    "        batch_size, seq_len = positions.shape\n",
    "        embeddings = torch.zeros(batch_size, seq_len, TIME_EMBEDDING_DIM, device=positions.device)\n",
    "        \n",
    "        # Normalize positions to [0, 1]\n",
    "        max_pos = positions.max(dim=1, keepdim=True)[0].float()\n",
    "        normalized_pos = positions.float() / (max_pos + 1e-8)\n",
    "        \n",
    "        div_term = torch.exp(torch.arange(0, TIME_EMBEDDING_DIM, 2, device=positions.device).float() * \n",
    "                            -(np.log(10000.0) / TIME_EMBEDDING_DIM))\n",
    "        \n",
    "        pos_scaled = normalized_pos.unsqueeze(-1) * div_term.unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        embeddings[:, :, 0::2] = torch.sin(pos_scaled)\n",
    "        embeddings[:, :, 1::2] = torch.cos(pos_scaled)\n",
    "        \n",
    "        return embeddings\n",
    "        \n",
    "    def forward(self, events, features, lengths):\n",
    "        if events.size(0) == 0:\n",
    "            return torch.zeros(0, 10, device=events.device)\n",
    "        \n",
    "        lengths = torch.clamp(lengths, min=1, max=events.size(1))\n",
    "        \n",
    "        # Get sinusoidal position embeddings\n",
    "        pos_emb = self.get_sincos_embeddings(events)\n",
    "        \n",
    "        # Project features\n",
    "        feat_emb = self.feature_proj(features.unsqueeze(-1))\n",
    "        \n",
    "        # Combine embeddings\n",
    "        combined = pos_emb + feat_emb\n",
    "        \n",
    "        # Pack sequences\n",
    "        packed = pack_padded_sequence(combined, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        # Classify\n",
    "        output = self.classifier(h_n[-1])\n",
    "        return output\n",
    "\n",
    "class LETE_LSTM_Fixed(nn.Module):\n",
    "    \"\"\"LSTM with LETE time embeddings - FIXED.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=784, hidden_dim=128, num_classes=10, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Initialize LETE\n",
    "        self.lete = LeTE(dim=TIME_EMBEDDING_DIM)\n",
    "        \n",
    "        # Feature projection\n",
    "        self.feature_proj = nn.Linear(1, TIME_EMBEDDING_DIM)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=TIME_EMBEDDING_DIM,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, events, features, lengths):\n",
    "        # Input validation\n",
    "        if events.size(0) == 0:\n",
    "            return torch.zeros(0, 10, device=events.device)\n",
    "        \n",
    "        # Clamp lengths to prevent issues\n",
    "        lengths = torch.clamp(lengths, min=1, max=events.size(1))\n",
    "        \n",
    "        # Normalize timestamps\n",
    "        max_pos = events.max(dim=1, keepdim=True)[0].float()\n",
    "        # Prevent division by zero\n",
    "        max_pos[max_pos == 0] = 1.0\n",
    "        timestamps = events.float() / max_pos\n",
    "        \n",
    "        # Get LETE embeddings\n",
    "        timestamps_3d = timestamps.unsqueeze(-1)\n",
    "        lete_emb = self.lete(timestamps_3d)\n",
    "        \n",
    "        # Handle shape mismatches\n",
    "        batch_size, seq_len = timestamps.shape\n",
    "        if lete_emb.shape != (batch_size, seq_len, TIME_EMBEDDING_DIM):\n",
    "            if lete_emb.dim() == 3:\n",
    "                # Take only what we need\n",
    "                lete_emb = lete_emb[:, :seq_len, :TIME_EMBEDDING_DIM]\n",
    "            else:\n",
    "                # Reshape as needed\n",
    "                lete_emb = lete_emb.view(batch_size, seq_len, -1)\n",
    "                if lete_emb.shape[2] != TIME_EMBEDDING_DIM:\n",
    "                    # Project to correct dimension\n",
    "                    if not hasattr(self, 'lete_proj'):\n",
    "                        self.lete_proj = nn.Linear(lete_emb.shape[2], TIME_EMBEDDING_DIM).to(lete_emb.device)\n",
    "                    lete_emb = self.lete_proj(lete_emb)\n",
    "        \n",
    "        # Clip to prevent numerical issues\n",
    "        lete_emb = torch.clamp(lete_emb, min=-1e3, max=1e3)\n",
    "        \n",
    "        # Project features\n",
    "        feat_emb = self.feature_proj(features.unsqueeze(-1))\n",
    "        \n",
    "        # Combine embeddings\n",
    "        combined = lete_emb + feat_emb\n",
    "        combined = F.relu(combined)\n",
    "        \n",
    "        # LSTM processing\n",
    "        packed = pack_padded_sequence(combined, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        # Classify\n",
    "        output = self.classifier(h_n[-1])\n",
    "        return output\n",
    "class KAN_MAMMOTE_LSTM_Fixed(nn.Module):\n",
    "    \"\"\"LSTM with KAN-MAMMOTE that processes the entire sequence.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=784, hidden_dim=128, num_classes=10, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Fix 1: Update timestamp projection dimension\n",
    "        # The input is a scalar (dimension 1), and the output needs to match input_feature_dim in KAN config\n",
    "        self.timestamp_proj = nn.Linear(1, 16)\n",
    "        \n",
    "        # Initialize KAN-MAMMOTE with appropriate settings\n",
    "        self.kan_config = KANMAMOTEConfig(\n",
    "            D_time=TIME_EMBEDDING_DIM,\n",
    "            d_model=LSTM_HIDDEN_DIM,\n",
    "            input_feature_dim=16,  # Must match output dim of timestamp_proj\n",
    "            output_dim_for_task=TIME_EMBEDDING_DIM,\n",
    "            K_top=4,\n",
    "            use_aux_features_router=False,\n",
    "            raw_event_feature_dim=1,\n",
    "            num_layers=1,\n",
    "            num_experts=4\n",
    "        )\n",
    "        \n",
    "        self.kan_mammote = KANMAMMOTE(self.kan_config)\n",
    "        \n",
    "        # Feature projection\n",
    "        self.feature_proj = nn.Linear(1, TIME_EMBEDDING_DIM)\n",
    "        \n",
    "        # Combine embeddings\n",
    "        self.combine = nn.Linear(TIME_EMBEDDING_DIM * 2, TIME_EMBEDDING_DIM)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=TIME_EMBEDDING_DIM,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, events, features, lengths):\n",
    "        # Input validation\n",
    "        if events.size(0) == 0:\n",
    "            return torch.zeros(0, self.num_classes, device=events.device)\n",
    "        \n",
    "        # Clamp lengths to prevent issues\n",
    "        lengths = torch.clamp(lengths, min=1, max=events.size(1))\n",
    "        \n",
    "        # Filter valid sequences\n",
    "        valid_mask = lengths > 0\n",
    "        if not valid_mask.any():\n",
    "            return torch.zeros(events.size(0), self.num_classes, device=events.device)\n",
    "        \n",
    "        events_valid = events[valid_mask]\n",
    "        features_valid = features[valid_mask]\n",
    "        lengths_valid = lengths[valid_mask]\n",
    "        \n",
    "        # Normalize timestamps\n",
    "        max_pos = events_valid.max(dim=1, keepdim=True)[0].float()\n",
    "        max_pos[max_pos == 0] = 1.0\n",
    "        timestamps = events_valid.float() / (max_pos + 1e-8)\n",
    "        \n",
    "        batch_size, max_seq_len = events_valid.shape\n",
    "        \n",
    "         # Create sequence mask to handle variable lengths\n",
    "        seq_mask = torch.arange(max_seq_len, device=lengths_valid.device)[None, :] < lengths_valid[:, None]\n",
    "        \n",
    "        # Process all positions at once - KEY OPTIMIZATION\n",
    "        \n",
    "        # 1. Project all timestamps\n",
    "        # Shape: [batch_size, seq_len, 1] -> [batch_size, seq_len, 16]\n",
    "        all_timestamp_proj = self.timestamp_proj(timestamps.unsqueeze(-1))\n",
    "        \n",
    "        # 2. Create empty features tensor matching the expected dimensions\n",
    "        # Shape: [batch_size, seq_len, 16]\n",
    "        all_features = torch.zeros(batch_size, max_seq_len, 16, device=timestamps.device)\n",
    "        \n",
    "        # 3. Apply mask to both tensors to handle padding properly\n",
    "        # This step is important to ensure we don't process padding tokens\n",
    "        masked_timestamp_proj = all_timestamp_proj * seq_mask.unsqueeze(-1).float()\n",
    "        masked_features = all_features * seq_mask.unsqueeze(-1).float()\n",
    "        \n",
    "        # 4. Process through KAN-MAMMOTE in a single forward pass\n",
    "        try:\n",
    "            # Reshape for processing\n",
    "            # From [batch_size, seq_len, 16] to [batch_size * seq_len, 16]\n",
    "            flat_timestamps = masked_timestamp_proj.view(-1, 16)\n",
    "            flat_features = masked_features.view(-1, 1, 16)  # Keep the seq_len dim of 1 for each position\n",
    "            \n",
    "            # Skip zeros (padding) to save computation\n",
    "            nonzero_mask = ~(flat_timestamps.sum(dim=-1) == 0)\n",
    "            if nonzero_mask.any():\n",
    "                nonzero_timestamps = flat_timestamps[nonzero_mask]\n",
    "                nonzero_features = flat_features[nonzero_mask]\n",
    "                \n",
    "                # Process through KAN-MAMMOTE\n",
    "                nonzero_outputs, _ = self.kan_mammote(nonzero_timestamps, nonzero_features)\n",
    "                if nonzero_outputs.dim() == 3 and nonzero_outputs.shape[1] == 1:\n",
    "                    # Remove the middle dimension\n",
    "                    nonzero_outputs = nonzero_outputs.squeeze(1)\n",
    "                # Initialize output tensor\n",
    "                flat_outputs = torch.zeros(\n",
    "                    flat_timestamps.size(0), TIME_EMBEDDING_DIM, \n",
    "                    device=flat_timestamps.device\n",
    "                )\n",
    "                \n",
    "                # Place outputs back\n",
    "                flat_outputs[nonzero_mask] = nonzero_outputs\n",
    "                \n",
    "                # Reshape back to [batch_size, seq_len, embedding_dim]\n",
    "                kan_embeddings = flat_outputs.view(batch_size, max_seq_len, -1)\n",
    "            else:\n",
    "                # Handle edge case where all are zeros\n",
    "                kan_embeddings = torch.zeros(batch_size, max_seq_len, TIME_EMBEDDING_DIM, device=timestamps.device)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing with KAN-MAMMOTE: {e}\")\n",
    "            print(f\"Input shapes - timestamp_proj: {masked_timestamp_proj.shape}, features: {masked_features.shape}\")\n",
    "            # Add more detailed error info\n",
    "            if 'nonzero_outputs' in locals():\n",
    "                print(f\"Output shape from KAN-MAMMOTE: {nonzero_outputs.shape}\")\n",
    "            if 'flat_outputs' in locals():\n",
    "                print(f\"Shape of flat_outputs: {flat_outputs.shape}\")\n",
    "            if 'nonzero_mask' in locals():\n",
    "                print(f\"Nonzero mask shape: {nonzero_mask.shape}, sum: {nonzero_mask.sum()}\")\n",
    "            \n",
    "            raise\n",
    "        \n",
    "        # Project features for the other branch\n",
    "        feat_emb = self.feature_proj(features_valid.unsqueeze(-1))\n",
    "        \n",
    "        # Combine embeddings from both pathways\n",
    "        combined_valid = torch.cat([kan_embeddings, feat_emb], dim=-1)\n",
    "        combined_valid = self.combine(combined_valid)\n",
    "        combined_valid = F.relu(combined_valid)\n",
    "        \n",
    "        # Apply sequence mask again to ensure we don't use padding in LSTM\n",
    "        combined_valid = combined_valid * seq_mask.unsqueeze(-1).float()\n",
    "        \n",
    "        # LSTM processing\n",
    "        packed = pack_padded_sequence(combined_valid, lengths_valid.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        # Classifier\n",
    "        valid_logits = self.classifier(h_n[-1])\n",
    "        \n",
    "        # Create full output tensor\n",
    "        full_logits = torch.zeros(events.size(0), self.num_classes, device=events.device)\n",
    "        full_logits[valid_mask] = valid_logits\n",
    "        \n",
    "        return full_logits\n",
    "    \n",
    "def train_model(model, train_loader, test_loader, model_name):\n",
    "    \"\"\"Train a single model with immediate error stopping.\"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': [],\n",
    "        'epochs': [], 'training_time': []\n",
    "    }\n",
    "    \n",
    "    best_test_acc = 0.0\n",
    "    \n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\", leave=False)\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_idx, (events, features, lengths, labels) in enumerate(train_pbar):\n",
    "            # No try-except here - let errors propagate and stop execution\n",
    "            events, features, lengths, labels = events.to(device), features.to(device), lengths.to(device), labels.to(device)\n",
    "            \n",
    "            # Debug info for first few batches\n",
    "            '''if batch_idx < 3:\n",
    "                print(f\"\\n📊 Batch {batch_idx} debug:\")\n",
    "                print(f\"  - events: shape={events.shape}, range=[{events.min().item()}, {events.max().item()}]\")\n",
    "                print(f\"  - features: shape={features.shape}, range=[{features.min().item()}, {features.max().item()}]\")\n",
    "                print(f\"  - lengths: shape={lengths.shape}, range=[{lengths.min().item()}, {lengths.max().item()}]\")\n",
    "                print(f\"  - labels: shape={labels.shape}, values={labels.tolist()}\")'''\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(events, features, lengths)\n",
    "            \n",
    "            # Check outputs and raise error if issues are found\n",
    "            if torch.isnan(outputs).any():\n",
    "                print(f\"⚠️ NaN detected in outputs at batch {batch_idx}!\")\n",
    "                raise ValueError(f\"NaN detected in model outputs at batch {batch_idx}\")\n",
    "                \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Check loss and raise error if issues are found\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(f\"⚠️ NaN/Inf loss detected at batch {batch_idx}: {loss.item()}\")\n",
    "                raise ValueError(f\"NaN or Inf loss value detected at batch {batch_idx}: {loss.item()}\")\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # Check gradients and raise error if issues are found\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None and (torch.isnan(param.grad).any() or torch.isinf(param.grad).any()):\n",
    "                    print(f\"⚠️ NaN/Inf gradient detected in {name}\")\n",
    "                    raise ValueError(f\"NaN or Inf gradient detected in parameter {name}\")\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP_NORM)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update tqdm postfix\n",
    "            train_pbar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{100*train_correct/train_total:.2f}%\")\n",
    "        \n",
    "        train_pbar.close()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        test_pbar = tqdm(test_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Test]\", leave=False)\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (events, features, lengths, labels) in enumerate(test_pbar):\n",
    "                # No try-except here - let errors propagate and stop execution\n",
    "                events, features, lengths, labels = events.to(device), features.to(device), lengths.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(events, features, lengths)\n",
    "                \n",
    "                # Check outputs and raise error if issues are found\n",
    "                if torch.isnan(outputs).any():\n",
    "                    print(f\"⚠️ NaN detected in test outputs at batch {batch_idx}!\")\n",
    "                    raise ValueError(f\"NaN detected in test model outputs at batch {batch_idx}\")\n",
    "                    \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Check loss and raise error if issues are found\n",
    "                if torch.isnan(loss) or torch.isinf(loss):\n",
    "                    print(f\"⚠️ NaN/Inf test loss detected at batch {batch_idx}: {loss.item()}\")\n",
    "                    raise ValueError(f\"NaN or Inf test loss value detected at batch {batch_idx}: {loss.item()}\")\n",
    "                \n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                test_pbar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{100*test_correct/test_total:.2f}%\")\n",
    "        \n",
    "        test_pbar.close()\n",
    "\n",
    "        # Calculate metrics\n",
    "        epoch_time = time.time() - start_time\n",
    "        train_acc = 100 * train_correct / max(train_total, 1)  # Avoid division by zero\n",
    "        test_acc = 100 * test_correct / max(test_total, 1)    # Avoid division by zero\n",
    "        avg_train_loss = train_loss / max(len(train_loader), 1)  # Avoid division by zero\n",
    "        avg_test_loss = test_loss / max(len(test_loader), 1)    # Avoid division by zero\n",
    "        \n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "        \n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_loss'].append(avg_test_loss)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        history['epochs'].append(epoch + 1)\n",
    "        history['training_time'].append(epoch_time)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{NUM_EPOCHS}: Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%, Time: {epoch_time:.1f}s')\n",
    "    \n",
    "    print(f\"✅ {model_name} training complete. Best test accuracy: {best_test_acc:.2f}%\")\n",
    "    return history, best_test_acc\n",
    "\n",
    "def plot_training_curves(results):\n",
    "    \"\"\"Plot training curves for all models.\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot training accuracy\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for model_name, history in results.items():\n",
    "        if 'train_acc' in history and len(history['train_acc']) > 0:\n",
    "            plt.plot(history['epochs'], history['train_acc'], label=model_name, marker='o')\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot test accuracy\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for model_name, history in results.items():\n",
    "        if 'test_acc' in history and len(history['test_acc']) > 0:\n",
    "            plt.plot(history['epochs'], history['test_acc'], label=model_name, marker='o')\n",
    "    plt.title('Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot training loss\n",
    "    plt.subplot(2, 2, 3)\n",
    "    for model_name, history in results.items():\n",
    "        if 'train_loss' in history and len(history['train_loss']) > 0:\n",
    "            plt.plot(history['epochs'], history['train_loss'], label=model_name, marker='o')\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot test loss\n",
    "    plt.subplot(2, 2, 4)\n",
    "    for model_name, history in results.items():\n",
    "        if 'test_loss' in history and len(history['test_loss']) > 0:\n",
    "            plt.plot(history['epochs'], history['test_loss'], label=model_name, marker='o')\n",
    "    plt.title('Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{RESULTS_DIR}/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✅ Training curves saved to {RESULTS_DIR}/training_curves.png\")\n",
    "\n",
    "print(\"✅ Setup complete! All imports and model definitions loaded.\")\n",
    "print(f\"✅ Device: {device}\")\n",
    "print(f\"✅ Results directory: {RESULTS_DIR}\")\n",
    "print(\"🚀 Ready to run the comparison!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43de4abe",
   "metadata": {},
   "source": [
    "Looking at the error trace, I can see there's a shape mismatch error occurring during the matrix multiplication in the neural network. The error \"mat1 and mat2 shapes cannot be multiplied (32x16 and 1x64)\" suggests that your KAN-MAMMOTE model has a dimension mismatch between the projected timestamps and the network's expected input shape.\n",
    "\n",
    "Let me create a test file to help diagnose this issue. I'll focus on testing the model initialization, forward pass, and the key component causing the error.\n",
    "\n",
    "\n",
    "\n",
    "Made changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23b87960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Running on GPU.\n"
     ]
    }
   ],
   "source": [
    "#check cuda\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Running on GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "298d066b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting LSTM Time Embedding Comparison - FIXED VERSION (STOP ON ERROR)...\n",
      "\n",
      "📁 Loading datasets...\n",
      "✅ Dataset loaded: 60000 train, 10000 test samples\n",
      "\n",
      "📊 Model Information:\n",
      "   True_Baseline: 200,458 parameters\n",
      "   Learnable_Position: 283,018 parameters\n",
      "   SinCos_LSTM: 232,842 parameters\n",
      "   LETE_LSTM: 252,650 parameters\n",
      "   KAN_MAMMOTE_LSTM: 418,862 parameters\n",
      "\n",
      "==================================================\n",
      "Starting training for True_Baseline\n",
      "==================================================\n",
      "Training True_Baseline...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e80138d8ec749a7af290aed7c8a758b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10 [Train]:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 164\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# Run the comparison\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# No try-except here - let errors propagate and stop execution\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m history, best_acc = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m results[model_name] = history\n\u001b[32m     86\u001b[39m best_accuracies[model_name] = best_acc\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 519\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, test_loader, model_name)\u001b[39m\n\u001b[32m    516\u001b[39m train_correct = \u001b[32m0\u001b[39m\n\u001b[32m    517\u001b[39m train_total = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_pbar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No try-except here - let errors propagate and stop execution\u001b[39;49;00m\n\u001b[32m    521\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Debug info for first few batches\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/kan_mammote/lib/python3.11/site-packages/tqdm/notebook.py:250\u001b[39m, in \u001b[36mtqdm_notebook.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    249\u001b[39m     it = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/kan_mammote/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/kan_mammote/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/kan_mammote/lib/python3.11/site-packages/torch/utils/data/dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/kan_mammote/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/kan_mammote/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mEventBasedMNIST.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     74\u001b[39m features = []\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m28\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m28\u001b[39m):\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m image[i, j] > \u001b[38;5;28mself\u001b[39m.threshold:\n\u001b[32m     79\u001b[39m             position = i * \u001b[32m28\u001b[39m + j  \u001b[38;5;66;03m# Flatten position\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function with improved error handling - STOP ON ERROR version.\"\"\"\n",
    "    print(\"🚀 Starting LSTM Time Embedding Comparison - FIXED VERSION (STOP ON ERROR)...\")\n",
    "    \n",
    "    try:\n",
    "        # Create datasets\n",
    "        print(\"\\n📁 Loading datasets...\")\n",
    "        train_dataset = EventBasedMNIST(root='./data', train=True, threshold=THRESHOLD, download=True)\n",
    "        test_dataset = EventBasedMNIST(root='./data', train=False, threshold=THRESHOLD, download=True)\n",
    "        \n",
    "        # FIXED: Validate datasets\n",
    "        if len(train_dataset) == 0 or len(test_dataset) == 0:\n",
    "            raise ValueError(\"Empty dataset!\")\n",
    "        \n",
    "        print(f\"✅ Dataset loaded: {len(train_dataset)} train, {len(test_dataset)} test samples\")\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=0)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR LOADING DATASET - STOPPING: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return  # Stop execution\n",
    "    \n",
    "    # Define models to compare\n",
    "    models = {\n",
    "        \n",
    "        'True_Baseline': TrueBaselineLSTM(\n",
    "            input_size=784,\n",
    "            hidden_dim=LSTM_HIDDEN_DIM,\n",
    "            num_classes=10,\n",
    "            dropout=DROPOUT_RATE\n",
    "        ),\n",
    "       'Learnable_Position': LearnablePositionLSTM(\n",
    "            input_size=784,\n",
    "            hidden_dim=LSTM_HIDDEN_DIM,\n",
    "            num_classes=10,\n",
    "            dropout=DROPOUT_RATE\n",
    "        ),\n",
    "        'SinCos_LSTM': SinCosLSTM(\n",
    "            input_size=784,\n",
    "            hidden_dim=LSTM_HIDDEN_DIM,\n",
    "            num_classes=10,\n",
    "            dropout=DROPOUT_RATE\n",
    "        ),\n",
    "        'LETE_LSTM': LETE_LSTM_Fixed(\n",
    "            input_size=784,\n",
    "            hidden_dim=LSTM_HIDDEN_DIM,\n",
    "            num_classes=10,\n",
    "            dropout=DROPOUT_RATE\n",
    "        ),\n",
    "        \n",
    "        'KAN_MAMMOTE_LSTM': KAN_MAMMOTE_LSTM_Fixed(\n",
    "            input_size=784,\n",
    "            hidden_dim=LSTM_HIDDEN_DIM,\n",
    "            num_classes=10,\n",
    "            dropout=DROPOUT_RATE\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Print model information\n",
    "    print(\"\\n📊 Model Information:\")\n",
    "    for name, model in models.items():\n",
    "        try:\n",
    "            param_count = count_parameters(model)\n",
    "            print(f\"   {name}: {param_count:,} parameters\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ ERROR COUNTING PARAMETERS FOR {name} - STOPPING: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return  # Stop execution if model parameter counting fails\n",
    "    \n",
    "    # Train all models\n",
    "    results = {}\n",
    "    best_accuracies = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\n\" + \"=\"*50)\n",
    "        print(f\"Starting training for {model_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # No try-except here - let errors propagate and stop execution\n",
    "        history, best_acc = train_model(model, train_loader, test_loader, model_name)\n",
    "        results[model_name] = history\n",
    "        best_accuracies[model_name] = best_acc\n",
    "        \n",
    "        # Clean up memory after each model\n",
    "        del model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Save results\n",
    "    print(\"\\n💾 Saving results...\")\n",
    "    \n",
    "    try:\n",
    "        # Save training histories\n",
    "        with open(f\"{RESULTS_DIR}/training_histories.json\", 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        # Save summary results\n",
    "        summary = {\n",
    "            'best_accuracies': best_accuracies,\n",
    "            'model_parameters': {name: count_parameters(models[name]) if name in models else 0 for name in best_accuracies.keys()},\n",
    "            'configuration': {\n",
    "                'batch_size': BATCH_SIZE,\n",
    "                'learning_rate': LEARNING_RATE,\n",
    "                'num_epochs': NUM_EPOCHS,\n",
    "                'lstm_hidden_dim': LSTM_HIDDEN_DIM,\n",
    "                'time_embedding_dim': TIME_EMBEDDING_DIM,\n",
    "                'dropout_rate': DROPOUT_RATE,\n",
    "                'threshold': THRESHOLD\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(f\"{RESULTS_DIR}/summary.json\", 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        # Create CSV summary\n",
    "        with open(f\"{RESULTS_DIR}/results_summary.csv\", 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['Model', 'Best_Accuracy', 'Parameters', 'Avg_Time_per_Epoch'])\n",
    "            \n",
    "            for model_name in best_accuracies.keys():\n",
    "                if model_name in results and len(results[model_name]['training_time']) > 0:\n",
    "                    avg_time = np.mean(results[model_name]['training_time'])\n",
    "                    params = count_parameters(models[model_name])  # Fixed parameter name\n",
    "                    writer.writerow([\n",
    "                        model_name,\n",
    "                        f\"{best_accuracies[model_name]:.4f}\",\n",
    "                        params,\n",
    "                        f\"{avg_time:.2f}\"\n",
    "                    ])\n",
    "        \n",
    "        # Create visualizations\n",
    "        if results:\n",
    "            plot_training_curves(results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR SAVING RESULTS - STOPPING: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return  # Stop execution\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n🎯 FINAL RESULTS SUMMARY:\")\n",
    "    print(\"=\" * 80)\n",
    "    for model_name, acc in best_accuracies.items():\n",
    "        params = count_parameters(models[model_name])\n",
    "        if model_name in results and len(results[model_name]['training_time']) > 0:\n",
    "            avg_time = np.mean(results[model_name]['training_time'])\n",
    "            print(f\"{model_name:20s}: {acc:.4f} acc | {params:7,} params | {avg_time:.1f}s/epoch\")\n",
    "    \n",
    "    # Find best model\n",
    "    if best_accuracies and any(acc > 0 for acc in best_accuracies.values()):\n",
    "        best_model = max(best_accuracies, key=best_accuracies.get)\n",
    "        print(f\"\\n🏆 Best Model: {best_model} (Accuracy: {best_accuracies[best_model]:.4f})\")\n",
    "    \n",
    "    print(f\"\\n💾 All results saved to: {RESULTS_DIR}\")\n",
    "    print(\"🎉 Comparison complete!\")\n",
    "\n",
    "# Run the comparison\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "752ef762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing the fixed implementation - STOP ON ERROR...\n",
      "✅ All imports successful\n",
      "✅ Device: cuda\n",
      "✅ Configuration loaded:\n",
      "   - Batch size: 32\n",
      "   - Learning rate: 0.001\n",
      "   - Time embedding dim: 64\n",
      "   - LSTM hidden dim: 128\n",
      "   - Epochs: 10\n",
      "\n",
      "📊 Testing Model Instantiation:\n",
      "Creating TrueBaselineLSTM...\n",
      "✅ TrueBaselineLSTM created successfully\n",
      "Creating LearnablePositionLSTM...\n",
      "✅ LearnablePositionLSTM created successfully\n",
      "Creating SinCosLSTM...\n",
      "✅ SinCosLSTM created successfully\n",
      "Creating LETE_LSTM_Fixed...\n",
      "✅ LETE_LSTM_Fixed created successfully\n",
      "Creating KAN_MAMMOTE_LSTM_Fixed...\n",
      "✅ KAN_MAMMOTE_LSTM_Fixed created successfully\n",
      "\n",
      "📊 Model Parameter Counts:\n",
      "   True_Baseline: 200,458 parameters\n",
      "   Learnable_Position: 283,018 parameters\n",
      "   SinCos_LSTM: 232,842 parameters\n",
      "   LETE_LSTM: 252,650 parameters\n",
      "   KAN_MAMMOTE_LSTM: 418,862 parameters\n",
      "✅ All models instantiated successfully\n",
      "\n",
      "🔍 Detailed inspection of KAN_MAMMOTE_LSTM model:\n",
      "\n",
      "📋 Model Structure:\n",
      "KAN_MAMMOTE_LSTM_Fixed(\n",
      "  (timestamp_proj): Linear(in_features=1, out_features=16, bias=True)\n",
      "  (kan_mammote): KANMAMMOTE(\n",
      "    (initial_feature_proj): Linear(in_features=16, out_features=128, bias=True)\n",
      "    (mamba_blocks): ModuleList(\n",
      "      (0): ContinuousMambaBlock(\n",
      "        (k_mote): K_MOTE(\n",
      "          (router): MoERouter(\n",
      "            (router_network): Sequential(\n",
      "              (0): Linear(in_features=1, out_features=64, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "              (3): ReLU()\n",
      "              (4): Linear(in_features=32, out_features=4, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (experts): ModuleDict(\n",
      "            (fourier): KANLayer(\n",
      "              (basis_function): FourierBasis()\n",
      "            )\n",
      "            (spline): MatrixKANLayer(\n",
      "              (base_fun): SiLU()\n",
      "            )\n",
      "            (gaussian): KANLayer(\n",
      "              (basis_function): GaussianKernelBasis()\n",
      "            )\n",
      "            (wavelet): KANLayer(\n",
      "              (basis_function): WaveletBasis()\n",
      "            )\n",
      "          )\n",
      "          (final_projection): Identity()\n",
      "          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (faster_kan_transform): FasterKAN(\n",
      "          (kan_transform): KANLayer(\n",
      "            (basis_function): GaussianKernelBasis()\n",
      "          )\n",
      "        )\n",
      "        (input_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (mamba_ssm): DynamicMambaSSM(\n",
      "          (in_proj): Linear(in_features=128, out_features=776, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (norm): RMSNorm()\n",
      "          (out_proj): Linear(in_features=256, out_features=128, bias=False)\n",
      "          (dt_modulation_proj): Linear(in_features=64, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (prediction_head): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (regularization_handler): KANMAMMOTE_RegularizationLosses()\n",
      "  )\n",
      "  (feature_proj): Linear(in_features=1, out_features=64, bias=True)\n",
      "  (combine): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (lstm): LSTM(64, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (classifier): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "📊 Key Component Info:\n",
      "KAN Config: <src.utils.config.KANMAMOTEConfig object at 0x1546b16a2990>\n",
      "KAN-MAMMOTE initialized: True\n",
      "Timestamp projector shape: in=1, out=16\n",
      "Feature projector shape: in=1, out=64\n",
      "Combiner shape: in=128, out=64\n",
      "LSTM input size: 64\n",
      "LSTM hidden size: 128\n",
      "Classifier shape: in=128, out=10\n",
      "\n",
      "📁 Testing Dataset Creation (small sample)...\n",
      "✅ Dataset created with 60000 samples\n",
      "\n",
      "📊 Testing single item retrieval:\n",
      "Sample 0 - events shape: (128,), features shape: (128,), label: 5\n",
      "Sample 0 - events range: [156, 682]\n",
      "Sample 0 - features range: [0.3059, 1.0000]\n",
      "\n",
      "📊 Testing DataLoader:\n",
      "✅ DataLoader working:\n",
      "   - Batch events shape: torch.Size([4, 141])\n",
      "   - Batch features shape: torch.Size([4, 141])\n",
      "   - Batch lengths: tensor([128, 141,  98,  74])\n",
      "   - Batch labels: tensor([5, 0, 4, 1])\n",
      "\n",
      "🧪 Testing KAN_MAMMOTE_LSTM with a single batch:\n",
      "✅ Forward pass successful!\n",
      "   - Output shape: torch.Size([4, 10])\n",
      "   - Output range: [-0.0869, 0.0820]\n",
      "\n",
      "🎉 Fix verification complete!\n",
      "🚀 You can now run main() in the next cell to start the full comparison!\n"
     ]
    }
   ],
   "source": [
    "# 🧪 Quick Test to Verify Everything Works - STOP ON ERROR\n",
    "print(\"🧪 Testing the fixed implementation - STOP ON ERROR...\")\n",
    "\n",
    "# Test if all variables are available\n",
    "print(\"✅ All imports successful\")\n",
    "print(f\"✅ Device: {device}\")\n",
    "print(f\"✅ Configuration loaded:\")\n",
    "print(f\"   - Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   - Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"   - Time embedding dim: {TIME_EMBEDDING_DIM}\")\n",
    "print(f\"   - LSTM hidden dim: {LSTM_HIDDEN_DIM}\")\n",
    "print(f\"   - Epochs: {NUM_EPOCHS}\")\n",
    "\n",
    "# Test model instantiation\n",
    "print(\"\\n📊 Testing Model Instantiation:\")\n",
    "# Only create one model at a time to isolate errors\n",
    "print(\"Creating TrueBaselineLSTM...\")\n",
    "true_baseline = TrueBaselineLSTM(hidden_dim=LSTM_HIDDEN_DIM, dropout=DROPOUT_RATE)\n",
    "print(\"✅ TrueBaselineLSTM created successfully\")\n",
    "\n",
    "print(\"Creating LearnablePositionLSTM...\")\n",
    "learnable_pos = LearnablePositionLSTM(hidden_dim=LSTM_HIDDEN_DIM, dropout=DROPOUT_RATE)\n",
    "print(\"✅ LearnablePositionLSTM created successfully\")\n",
    "\n",
    "print(\"Creating SinCosLSTM...\")\n",
    "sincos_lstm = SinCosLSTM(hidden_dim=LSTM_HIDDEN_DIM, dropout=DROPOUT_RATE)\n",
    "print(\"✅ SinCosLSTM created successfully\")\n",
    "\n",
    "print(\"Creating LETE_LSTM_Fixed...\")\n",
    "lete_lstm = LETE_LSTM_Fixed(hidden_dim=LSTM_HIDDEN_DIM, dropout=DROPOUT_RATE)\n",
    "print(\"✅ LETE_LSTM_Fixed created successfully\")\n",
    "\n",
    "print(\"Creating KAN_MAMMOTE_LSTM_Fixed...\")\n",
    "kan_model = KAN_MAMMOTE_LSTM_Fixed(hidden_dim=LSTM_HIDDEN_DIM, dropout=DROPOUT_RATE)\n",
    "print(\"✅ KAN_MAMMOTE_LSTM_Fixed created successfully\")\n",
    "\n",
    "# Store models for parameter counting\n",
    "test_models = {\n",
    "    'True_Baseline': true_baseline,\n",
    "    'Learnable_Position': learnable_pos,\n",
    "    'SinCos_LSTM': sincos_lstm,\n",
    "    'LETE_LSTM': lete_lstm,\n",
    "    'KAN_MAMMOTE_LSTM': kan_model\n",
    "}\n",
    "\n",
    "print(\"\\n📊 Model Parameter Counts:\")\n",
    "for name, model in test_models.items():\n",
    "    params = count_parameters(model)\n",
    "    print(f\"   {name}: {params:,} parameters\")\n",
    "\n",
    "print(\"✅ All models instantiated successfully\")\n",
    "\n",
    "# Test model internals - KAN-MAMMOTE model\n",
    "print(\"\\n🔍 Detailed inspection of KAN_MAMMOTE_LSTM model:\")\n",
    "\n",
    "# Print model structure\n",
    "print(\"\\n📋 Model Structure:\")\n",
    "print(kan_model)\n",
    "\n",
    "# Check key components\n",
    "print(\"\\n📊 Key Component Info:\")\n",
    "print(f\"KAN Config: {kan_model.kan_config}\")\n",
    "print(f\"KAN-MAMMOTE initialized: {kan_model.kan_mammote is not None}\")\n",
    "print(f\"Timestamp projector shape: in={kan_model.timestamp_proj.in_features}, out={kan_model.timestamp_proj.out_features}\")\n",
    "print(f\"Feature projector shape: in={kan_model.feature_proj.in_features}, out={kan_model.feature_proj.out_features}\")\n",
    "print(f\"Combiner shape: in={kan_model.combine.in_features}, out={kan_model.combine.out_features}\")\n",
    "print(f\"LSTM input size: {kan_model.lstm.input_size}\")\n",
    "print(f\"LSTM hidden size: {kan_model.lstm.hidden_size}\")\n",
    "print(f\"Classifier shape: in={kan_model.classifier.in_features}, out={kan_model.classifier.out_features}\")\n",
    "\n",
    "# Test dataset creation\n",
    "print(\"\\n📁 Testing Dataset Creation (small sample)...\")\n",
    "# Create a tiny test dataset to verify it works\n",
    "test_dataset = EventBasedMNIST(root='./data', train=True, threshold=THRESHOLD, download=True)\n",
    "print(f\"✅ Dataset created with {len(test_dataset)} samples\")\n",
    "\n",
    "# Test getting a single item\n",
    "print(\"\\n📊 Testing single item retrieval:\")\n",
    "events, features, label = test_dataset[0]\n",
    "print(f\"Sample 0 - events shape: {events.shape}, features shape: {features.shape}, label: {label}\")\n",
    "print(f\"Sample 0 - events range: [{events.min()}, {events.max()}]\")\n",
    "print(f\"Sample 0 - features range: [{features.min():.4f}, {features.max():.4f}]\")\n",
    "\n",
    "# Test data loader\n",
    "print(\"\\n📊 Testing DataLoader:\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "batch = next(iter(test_loader))\n",
    "events, features, lengths, labels = batch\n",
    "\n",
    "print(f\"✅ DataLoader working:\")\n",
    "print(f\"   - Batch events shape: {events.shape}\")\n",
    "print(f\"   - Batch features shape: {features.shape}\")\n",
    "print(f\"   - Batch lengths: {lengths}\")\n",
    "print(f\"   - Batch labels: {labels}\")\n",
    "\n",
    "# Test data loader with KAN model\n",
    "print(\"\\n🧪 Testing KAN_MAMMOTE_LSTM with a single batch:\")\n",
    "# Move batch to device\n",
    "events = events.to(device)\n",
    "features = features.to(device)\n",
    "lengths = lengths.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Create model and move to device\n",
    "test_kan_model = KAN_MAMMOTE_LSTM_Fixed(hidden_dim=LSTM_HIDDEN_DIM, dropout=DROPOUT_RATE).to(device)\n",
    "\n",
    "# Test forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = test_kan_model(events, features, lengths)\n",
    "    \n",
    "print(f\"✅ Forward pass successful!\")\n",
    "print(f\"   - Output shape: {outputs.shape}\")\n",
    "print(f\"   - Output range: [{outputs.min().item():.4f}, {outputs.max().item():.4f}]\")\n",
    "\n",
    "# Clean up\n",
    "for model in test_models.values():\n",
    "    del model\n",
    "del test_kan_model\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n🎉 Fix verification complete!\")\n",
    "print(\"🚀 You can now run main() in the next cell to start the full comparison!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2da00d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing the fixed KAN_MAMMOTE_LSTM_Fixed implementation...\n",
      "\n",
      "📊 Test batch shapes:\n",
      "Events: torch.Size([4, 141])\n",
      "Features: torch.Size([4, 141])\n",
      "Lengths: tensor([128, 141,  98,  74], device='cuda:0')\n",
      "Labels: tensor([5, 0, 4, 1], device='cuda:0')\n",
      "\n",
      "🔄 Running forward pass with fixed model...\n",
      "\n",
      "✅ Forward pass SUCCESSFUL!\n",
      "Output shape: torch.Size([4, 10])\n",
      "Output range: [-0.1039, 0.1049]\n",
      "\n",
      "🔄 Testing backpropagation...\n",
      "✅ Backpropagation SUCCESSFUL! Loss: 2.3339\n",
      "\n",
      "🎉 KAN_MAMMOTE_LSTM_Fixed testing complete!\n",
      "\n",
      "📊 Test batch shapes:\n",
      "Events: torch.Size([4, 141])\n",
      "Features: torch.Size([4, 141])\n",
      "Lengths: tensor([128, 141,  98,  74], device='cuda:0')\n",
      "Labels: tensor([5, 0, 4, 1], device='cuda:0')\n",
      "\n",
      "🔄 Running forward pass with fixed model...\n",
      "\n",
      "✅ Forward pass SUCCESSFUL!\n",
      "Output shape: torch.Size([4, 10])\n",
      "Output range: [-0.1039, 0.1049]\n",
      "\n",
      "🔄 Testing backpropagation...\n",
      "✅ Backpropagation SUCCESSFUL! Loss: 2.3339\n",
      "\n",
      "🎉 KAN_MAMMOTE_LSTM_Fixed testing complete!\n"
     ]
    }
   ],
   "source": [
    "# 🧪 Testing the fixed KAN_MAMMOTE_LSTM_Fixed model specifically\n",
    "print(\"🧪 Testing the fixed KAN_MAMMOTE_LSTM_Fixed implementation...\")\n",
    "\n",
    "# Create a small test dataset\n",
    "test_dataset = EventBasedMNIST(root='./data', train=True, threshold=THRESHOLD, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "batch = next(iter(test_loader))\n",
    "events, features, lengths, labels = batch\n",
    "\n",
    "# Move batch to device\n",
    "events = events.to(device)\n",
    "features = features.to(device)\n",
    "lengths = lengths.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "print(f\"\\n📊 Test batch shapes:\")\n",
    "print(f\"Events: {events.shape}\")\n",
    "print(f\"Features: {features.shape}\")\n",
    "print(f\"Lengths: {lengths}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "\n",
    "# Create model and move to device\n",
    "test_kan_model = KAN_MAMMOTE_LSTM_Fixed(hidden_dim=LSTM_HIDDEN_DIM, dropout=DROPOUT_RATE).to(device)\n",
    "\n",
    "# Test forward pass with detailed error capture\n",
    "try:\n",
    "    print(\"\\n🔄 Running forward pass with fixed model...\")\n",
    "    with torch.no_grad():\n",
    "        outputs = test_kan_model(events, features, lengths)\n",
    "        \n",
    "    print(f\"\\n✅ Forward pass SUCCESSFUL!\")\n",
    "    print(f\"Output shape: {outputs.shape}\")\n",
    "    print(f\"Output range: [{outputs.min().item():.4f}, {outputs.max().item():.4f}]\")\n",
    "    \n",
    "    # Test backpropagation\n",
    "    print(\"\\n🔄 Testing backpropagation...\")\n",
    "    optimizer = torch.optim.Adam(test_kan_model.parameters(), lr=0.001)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = test_kan_model(events, features, lengths)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"✅ Backpropagation SUCCESSFUL! Loss: {loss.item():.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ FORWARD PASS FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Clean up\n",
    "del test_kan_model\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n🎉 KAN_MAMMOTE_LSTM_Fixed testing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c4f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

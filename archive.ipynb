{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68687db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "üî¨ LSTM Time Embedding Comparison Script\n",
    "=========================================\n",
    "\n",
    "This script compares the performance of different LSTM variants with various time embeddings\n",
    "on the Event-Based MNIST dataset:\n",
    "\n",
    "1. **Baseline LSTM**: No time embedding (raw pixel positions)\n",
    "2. **LSTM + Sin/Cos**: Simple sinusoidal position encoding\n",
    "3. **LSTM + LETE**: Learning Time Embedding (LeTE)\n",
    "4. **LSTM + KAN-MAMMOTE**: KAN-MAMMOTE time embedding\n",
    "\n",
    "Each model is trained and evaluated on the same data with identical hyperparameters\n",
    "to ensure fair comparison.\n",
    "\n",
    "Author: Generated for KAN-MAMMOTE Project\n",
    "Date: July 2025\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = '/home/s2516027/kan-mammote'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import our models\n",
    "from src.models.kan_mammote import KAN_MAMOTE_Model\n",
    "from src.LETE.LeTE import CombinedLeTE\n",
    "from src.utils.config import KANMAMOTEConfig\n",
    "\n",
    "print(\"üöÄ LSTM Time Embedding Comparison Script\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# üîß CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Training configuration\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 5\n",
    "LSTM_HIDDEN_DIM = 128\n",
    "TIME_EMBEDDING_DIM = 32\n",
    "DROPOUT_RATE = 0.2\n",
    "THRESHOLD = 0.9  # MNIST pixel threshold for events\n",
    "\n",
    "# Results directory\n",
    "RESULTS_DIR = \"results/lstm_comparison\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"üìä Training Configuration:\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   LSTM Hidden Dim: {LSTM_HIDDEN_DIM}\")\n",
    "print(f\"   Time Embedding Dim: {TIME_EMBEDDING_DIM}\")\n",
    "\n",
    "# ============================================================================\n",
    "# üìÅ EVENT-BASED MNIST DATASET\n",
    "# ============================================================================\n",
    "\n",
    "class EventBasedMNIST(Dataset):\n",
    "    \"\"\"\n",
    "    Convert MNIST images to event-based sequences.\n",
    "    Each non-zero pixel becomes an event with timestamp = pixel position.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root='./data', train=True, threshold=0.9, transform=None, download=True):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.threshold = threshold\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load MNIST dataset\n",
    "        if transform is None:\n",
    "            transform = transforms.ToTensor()\n",
    "        \n",
    "        self.data = torchvision.datasets.MNIST(\n",
    "            root=self.root, \n",
    "            train=self.train, \n",
    "            transform=transform, \n",
    "            download=download\n",
    "        )\n",
    "        \n",
    "        # Pre-process all images to event sequences\n",
    "        self.event_data = []\n",
    "        self.labels = []\n",
    "        \n",
    "        print(f\"üìä Processing {'training' if train else 'test'} set to events...\")\n",
    "        \n",
    "        for idx in tqdm(range(len(self.data)), desc=\"Converting to events\"):\n",
    "            img, label = self.data[idx]\n",
    "            # Flatten image to 1D (784 pixels for 28x28)\n",
    "            img_flat = img.view(-1)  # (784,)\n",
    "            \n",
    "            # Find pixels above threshold (events)\n",
    "            events = torch.nonzero(img_flat > self.threshold).squeeze()\n",
    "            \n",
    "            # Handle edge cases\n",
    "            if events.dim() == 0:  # Single event\n",
    "                events = events.unsqueeze(0)\n",
    "            elif len(events) == 0:  # No events\n",
    "                events = torch.tensor([0])  # Add dummy event\n",
    "                \n",
    "            # Sort events by position (timestamp order)\n",
    "            events = torch.sort(events).values\n",
    "            \n",
    "            # Get intensities for features\n",
    "            intensities = img_flat[events]\n",
    "            features = intensities.unsqueeze(1)  # (seq_len, 1)\n",
    "            \n",
    "            self.event_data.append((events, features))\n",
    "            self.labels.append(label)\n",
    "        \n",
    "        print(f\"‚úÖ Processed {len(self.event_data)} samples\")\n",
    "        avg_events = sum(len(events) for events, _ in self.event_data) / len(self.event_data)\n",
    "        print(f\"   Average events per sample: {avg_events:.1f}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.event_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        events, features = self.event_data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return events, features, len(events), label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for variable-length sequences.\"\"\"\n",
    "    events_list = []\n",
    "    features_list = []\n",
    "    lengths = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for events, features, length, label in batch:\n",
    "        events_list.append(events)\n",
    "        features_list.append(features)\n",
    "        lengths.append(length)\n",
    "        labels_list.append(label)\n",
    "    \n",
    "    # Pad sequences\n",
    "    padded_events = pad_sequence(events_list, batch_first=True, padding_value=0)\n",
    "    padded_features = pad_sequence(features_list, batch_first=True, padding_value=0.0)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    lengths_tensor = torch.tensor(lengths, dtype=torch.long)\n",
    "    labels_tensor = torch.tensor(labels_list, dtype=torch.long)\n",
    "    \n",
    "    return padded_events, padded_features, lengths_tensor, labels_tensor\n",
    "\n",
    "# ============================================================================\n",
    "# üèóÔ∏è MODEL ARCHITECTURES\n",
    "# ============================================================================\n",
    "\n",
    "class BaselineLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Baseline LSTM with no time embedding.\n",
    "    Uses raw pixel positions as input.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=784, hidden_dim=128, num_classes=10, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Simple position embedding (learnable)\n",
    "        self.position_embedding = nn.Embedding(input_size, TIME_EMBEDDING_DIM)\n",
    "        \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=TIME_EMBEDDING_DIM,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, events, features, lengths):\n",
    "        # Simple position embedding\n",
    "        embedded = self.position_embedding(events)  # (batch, seq_len, emb_dim)\n",
    "        \n",
    "        # Pack for LSTM\n",
    "        packed = pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        # Use last hidden state\n",
    "        output = self.classifier(h_n[-1])\n",
    "        return output\n",
    "\n",
    "class SinCosLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM with Sinusoidal/Cosine position encoding.\n",
    "    Uses fixed sin/cos functions for time embedding.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=784, hidden_dim=128, num_classes=10, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = TIME_EMBEDDING_DIM\n",
    "        \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=TIME_EMBEDDING_DIM,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def get_sincos_embedding(self, positions):\n",
    "        \"\"\"Generate sinusoidal position embeddings.\"\"\"\n",
    "        batch_size, seq_len = positions.shape\n",
    "        device = positions.device\n",
    "        \n",
    "        # Normalize positions to [0, 1]\n",
    "        positions_norm = positions.float() / 784.0\n",
    "        \n",
    "        # Create embedding\n",
    "        embedding = torch.zeros(batch_size, seq_len, self.embedding_dim, device=device)\n",
    "        \n",
    "        # Half dimensions for sin, half for cos\n",
    "        half_dim = self.embedding_dim // 2\n",
    "        \n",
    "        # Generate frequencies\n",
    "        freqs = torch.exp(torch.arange(half_dim, device=device) * \n",
    "                         -(np.log(10000.0) / half_dim))\n",
    "        \n",
    "        # Apply sin/cos\n",
    "        args = positions_norm.unsqueeze(-1) * freqs.unsqueeze(0).unsqueeze(0)\n",
    "        embedding[:, :, 0::2] = torch.sin(args)\n",
    "        embedding[:, :, 1::2] = torch.cos(args)\n",
    "        \n",
    "        return embedding\n",
    "        \n",
    "    def forward(self, events, features, lengths):\n",
    "        # Sin/Cos position embedding\n",
    "        embedded = self.get_sincos_embedding(events)\n",
    "        \n",
    "        # Pack for LSTM\n",
    "        packed = pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        # Use last hidden state\n",
    "        output = self.classifier(h_n[-1])\n",
    "        return output\n",
    "\n",
    "class LETE_LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM with LETE (Learning Time Embedding).\n",
    "    Uses learnable time encoding from the LETE paper.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=784, hidden_dim=128, num_classes=10, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # LETE time encoder\n",
    "        self.time_encoder = CombinedLeTE(\n",
    "            dim=TIME_EMBEDDING_DIM,\n",
    "            p=0.5,  # 50% Fourier, 50% Spline\n",
    "            layer_norm=True,\n",
    "            scale=True\n",
    "        )\n",
    "        \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=TIME_EMBEDDING_DIM,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, events, features, lengths):\n",
    "        # Filter valid sequences\n",
    "        valid_mask = lengths > 0\n",
    "        if not valid_mask.any():\n",
    "            batch_size = events.size(0)\n",
    "            return torch.zeros(batch_size, 10, device=events.device)\n",
    "        \n",
    "        events_valid = events[valid_mask]\n",
    "        lengths_valid = lengths[valid_mask]\n",
    "        \n",
    "        # Normalize events to [0, 1] for LETE\n",
    "        events_norm = events_valid.float() / 784.0\n",
    "        \n",
    "        # LETE encoding\n",
    "        embedded = self.time_encoder(events_norm)\n",
    "        \n",
    "        # Pack for LSTM\n",
    "        lengths_valid = torch.clamp(lengths_valid, min=1)\n",
    "        packed = pack_padded_sequence(embedded, lengths_valid.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        # Classify\n",
    "        valid_logits = self.classifier(h_n[-1])\n",
    "        \n",
    "        # Create full output\n",
    "        batch_size = events.size(0)\n",
    "        full_logits = torch.zeros(batch_size, 10, device=events.device)\n",
    "        full_logits[valid_mask] = valid_logits\n",
    "        \n",
    "        return full_logits\n",
    "\n",
    "class KAN_MAMMOTE_LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM with KAN-MAMMOTE time embedding.\n",
    "    Uses the KAN-MAMMOTE model for sophisticated time representation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=784, hidden_dim=128, num_classes=10, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # KAN-MAMMOTE configuration\n",
    "        self.kan_config = KANMAMOTEConfig(\n",
    "            D_time=TIME_EMBEDDING_DIM,\n",
    "            num_experts=4,\n",
    "            hidden_dim_mamba=32,\n",
    "            state_dim_mamba=8,\n",
    "            num_mamba_layers=1,\n",
    "            gamma=0.3,\n",
    "            use_aux_features_router=False,\n",
    "            raw_event_feature_dim=16,\n",
    "            K_top=4,\n",
    "            kan_grid_size=5,\n",
    "            kan_grid_min=-2.0,\n",
    "            kan_grid_max=2.0,\n",
    "            kan_spline_scale=0.5,\n",
    "            kan_num_layers=1,\n",
    "            kan_hidden_dim=32\n",
    "        )\n",
    "        \n",
    "        # KAN-MAMMOTE model\n",
    "        self.kan_mammote = KAN_MAMOTE_Model(self.kan_config)\n",
    "        \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=TIME_EMBEDDING_DIM,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, events, features, lengths):\n",
    "        # Filter valid sequences\n",
    "        valid_mask = lengths > 0\n",
    "        if not valid_mask.any():\n",
    "            batch_size = events.size(0)\n",
    "            return torch.zeros(batch_size, 10, device=events.device)\n",
    "        \n",
    "        events_valid = events[valid_mask]\n",
    "        features_valid = features[valid_mask]\n",
    "        lengths_valid = lengths[valid_mask]\n",
    "        \n",
    "        # Prepare timestamps for KAN-MAMMOTE (normalize to [0, 1])\n",
    "        timestamps = events_valid.float() / 784.0\n",
    "        timestamps = timestamps.unsqueeze(-1)  # (batch, seq_len, 1)\n",
    "        \n",
    "        # Use features as auxiliary features\n",
    "        aux_features = features_valid\n",
    "        \n",
    "        # Get KAN-MAMMOTE embeddings\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                kan_output, _ = self.kan_mammote(timestamps, aux_features)\n",
    "            embedded = kan_output\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: KAN-MAMMOTE failed ({e}), using fallback\")\n",
    "            # Fallback to simple embedding\n",
    "            embedded = torch.randn_like(timestamps.expand(-1, -1, TIME_EMBEDDING_DIM))\n",
    "        \n",
    "        # Pack for LSTM\n",
    "        lengths_valid = torch.clamp(lengths_valid, min=1)\n",
    "        packed = pack_padded_sequence(embedded, lengths_valid.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        # Classify\n",
    "        valid_logits = self.classifier(h_n[-1])\n",
    "        \n",
    "        # Create full output\n",
    "        batch_size = events.size(0)\n",
    "        full_logits = torch.zeros(batch_size, 10, device=events.device)\n",
    "        full_logits[valid_mask] = valid_logits\n",
    "        \n",
    "        return full_logits\n",
    "\n",
    "# ============================================================================\n",
    "# üèÉ TRAINING AND EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, criterion, device):\n",
    "    \"\"\"Train model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for events, features, lengths, labels in tqdm(data_loader, desc=\"Training\"):\n",
    "        events = events.to(device)\n",
    "        features = features.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(events, features, lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    \"\"\"Evaluate model on test set.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for events, features, lengths, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            events = events.to(device)\n",
    "            features = features.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(events, features, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def train_model(model, train_loader, test_loader, model_name):\n",
    "    \"\"\"Train a model and return training history.\"\"\"\n",
    "    print(f\"\\nüöÄ Training {model_name}...\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': [],\n",
    "        'epochs': [],\n",
    "        'training_time': []\n",
    "    }\n",
    "    \n",
    "    best_test_acc = 0.0\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        # Evaluate\n",
    "        test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        # Save history\n",
    "        history['epochs'].append(epoch + 1)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        history['training_time'].append(epoch_time)\n",
    "        \n",
    "        # Update best accuracy\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), f\"{RESULTS_DIR}/{model_name}_best.pth\")\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Epoch {epoch+1:2d}/{NUM_EPOCHS} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f} | \"\n",
    "              f\"Time: {epoch_time:.1f}s\")\n",
    "    \n",
    "    print(f\"‚úÖ {model_name} training complete! Best test accuracy: {best_test_acc:.4f}\")\n",
    "    \n",
    "    return history, best_test_acc\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count trainable parameters in a model.\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# ============================================================================\n",
    "# üìä VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def plot_training_curves(results):\n",
    "    \"\"\"Plot training curves for all models.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    colors = ['blue', 'green', 'red', 'orange']\n",
    "    \n",
    "    for i, (model_name, history) in enumerate(results.items()):\n",
    "        color = colors[i % len(colors)]\n",
    "        \n",
    "        # Training/Test Loss\n",
    "        axes[0, 0].plot(history['epochs'], history['train_loss'], \n",
    "                       color=color, linestyle='-', label=f'{model_name} (Train)')\n",
    "        axes[0, 0].plot(history['epochs'], history['test_loss'], \n",
    "                       color=color, linestyle='--', label=f'{model_name} (Test)')\n",
    "        \n",
    "        # Training/Test Accuracy\n",
    "        axes[0, 1].plot(history['epochs'], history['train_acc'], \n",
    "                       color=color, linestyle='-', label=f'{model_name} (Train)')\n",
    "        axes[0, 1].plot(history['epochs'], history['test_acc'], \n",
    "                       color=color, linestyle='--', label=f'{model_name} (Test)')\n",
    "        \n",
    "        # Training Time per Epoch\n",
    "        axes[1, 0].plot(history['epochs'], history['training_time'], \n",
    "                       color=color, marker='o', label=model_name)\n",
    "        \n",
    "        # Final Test Accuracy Bar\n",
    "        final_acc = history['test_acc'][-1]\n",
    "        axes[1, 1].bar(i, final_acc, color=color, alpha=0.7, label=model_name)\n",
    "    \n",
    "    # Customize plots\n",
    "    axes[0, 0].set_title('Training vs Test Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].set_title('Training vs Test Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 0].set_title('Training Time per Epoch')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Time (seconds)')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 1].set_title('Final Test Accuracy')\n",
    "    axes[1, 1].set_xlabel('Model')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    axes[1, 1].set_xticks(range(len(results)))\n",
    "    axes[1, 1].set_xticklabels(list(results.keys()), rotation=45)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/training_curves.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# üéØ MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    print(\"üöÄ Starting LSTM Time Embedding Comparison...\")\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"\\nüìÅ Loading datasets...\")\n",
    "    train_dataset = EventBasedMNIST(root='./data', train=True, threshold=THRESHOLD, download=True)\n",
    "    test_dataset = EventBasedMNIST(root='./data', train=False, threshold=THRESHOLD, download=True)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    # Define models to compare\n",
    "    models = {\n",
    "        'Baseline_LSTM': BaselineLSTM(\n",
    "            input_size=784,\n",
    "            hidden_dim=LSTM_HIDDEN_DIM,\n",
    "            num_classes=10,\n",
    "            dropout=DROPOUT_RATE\n",
    "        ),\n",
    "        'SinCos_LSTM': SinCosLSTM(\n",
    "            input_size=784,\n",
    "            hidden_dim=LSTM_HIDDEN_DIM,\n",
    "            num_classes=10,\n",
    "            dropout=DROPOUT_RATE\n",
    "        ),\n",
    "        'LETE_LSTM': LETE_LSTM(\n",
    "            input_size=784,\n",
    "            hidden_dim=LSTM_HIDDEN_DIM,\n",
    "            num_classes=10,\n",
    "            dropout=DROPOUT_RATE\n",
    "        ),\n",
    "        'KAN_MAMMOTE_LSTM': KAN_MAMMOTE_LSTM(\n",
    "            input_size=784,\n",
    "            hidden_dim=LSTM_HIDDEN_DIM,\n",
    "            num_classes=10,\n",
    "            dropout=DROPOUT_RATE\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Print model information\n",
    "    print(\"\\nüìä Model Information:\")\n",
    "    for name, model in models.items():\n",
    "        param_count = count_parameters(model)\n",
    "        print(f\"   {name}: {param_count:,} parameters\")\n",
    "    \n",
    "    # Train all models\n",
    "    results = {}\n",
    "    best_accuracies = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        history, best_acc = train_model(model, train_loader, test_loader, model_name)\n",
    "        results[model_name] = history\n",
    "        best_accuracies[model_name] = best_acc\n",
    "    \n",
    "    # Save results\n",
    "    print(\"\\nüíæ Saving results...\")\n",
    "    \n",
    "    # Save training histories\n",
    "    with open(f\"{RESULTS_DIR}/training_histories.json\", 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    # Save summary results\n",
    "    summary = {\n",
    "        'best_accuracies': best_accuracies,\n",
    "        'model_parameters': {name: count_parameters(model) for name, model in models.items()},\n",
    "        'configuration': {\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'learning_rate': LEARNING_RATE,\n",
    "            'num_epochs': NUM_EPOCHS,\n",
    "            'lstm_hidden_dim': LSTM_HIDDEN_DIM,\n",
    "            'time_embedding_dim': TIME_EMBEDDING_DIM,\n",
    "            'dropout_rate': DROPOUT_RATE,\n",
    "            'threshold': THRESHOLD\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(f\"{RESULTS_DIR}/summary.json\", 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    # Create CSV summary\n",
    "    with open(f\"{RESULTS_DIR}/results_summary.csv\", 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Model', 'Best_Accuracy', 'Parameters', 'Avg_Time_per_Epoch'])\n",
    "        \n",
    "        for model_name in models.keys():\n",
    "            avg_time = np.mean(results[model_name]['training_time'])\n",
    "            writer.writerow([\n",
    "                model_name,\n",
    "                f\"{best_accuracies[model_name]:.4f}\",\n",
    "                count_parameters(models[model_name]),\n",
    "                f\"{avg_time:.2f}\"\n",
    "            ])\n",
    "    \n",
    "    # Create visualizations\n",
    "    plot_training_curves(results)\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\nüéØ FINAL RESULTS SUMMARY:\")\n",
    "    print(\"=\" * 60)\n",
    "    for model_name, acc in best_accuracies.items():\n",
    "        params = count_parameters(models[model_name])\n",
    "        avg_time = np.mean(results[model_name]['training_time'])\n",
    "        print(f\"{model_name:20s}: {acc:.4f} acc | {params:7,} params | {avg_time:.1f}s/epoch\")\n",
    "    \n",
    "    # Find best model\n",
    "    best_model = max(best_accuracies, key=best_accuracies.get)\n",
    "    print(f\"\\nüèÜ Best Model: {best_model} (Accuracy: {best_accuracies[best_model]:.4f})\")\n",
    "    \n",
    "    print(f\"\\nüíæ All results saved to: {RESULTS_DIR}\")\n",
    "    print(\"üéâ Comparison complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374fdfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

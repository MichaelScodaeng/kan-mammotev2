{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39296ca9",
   "metadata": {},
   "source": [
    "# üéØ Comprehensive MNIST Embedding Comparison\n",
    "\n",
    "This notebook compares the performance of different time embedding approaches on MNIST:\n",
    "1. **Baseline LSTM** - No time embedding (raw pixel positions)\n",
    "2. **LSTM + LETE** - With Learning Time Embedding (LeTE)\n",
    "3. **LSTM + KAN-MAMMOTE** - With Improved KAN-MAMMOTE embedding\n",
    "\n",
    "## üìä Key Metrics to Compare:\n",
    "- **Accuracy**: Classification performance\n",
    "- **Training Speed**: Time per epoch\n",
    "- **Parameter Count**: Model complexity\n",
    "- **Convergence**: Training stability\n",
    "- **Temporal Modeling**: How well each method captures temporal patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4583ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üì¶ IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our models\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "from src.models import KAN_MAMMOTE_Model, ImprovedKANMAMOTE  # Improved version as default\n",
    "from src.LETE.LeTE import CombinedLeTE\n",
    "from src.utils.config import KANMAMOTEConfig\n",
    "\n",
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b60b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fde245",
   "metadata": {},
   "source": [
    "## üìÅ Data Setup\n",
    "\n",
    "We'll convert MNIST images to event-based sequences where each non-zero pixel becomes an event with:\n",
    "- **Timestamp**: Pixel position (row * width + col)\n",
    "- **Features**: Pixel intensity (optional)\n",
    "- **Label**: Digit class (0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a14715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ All imports successful!\n",
      "üîß Using device: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "üé≤ Creating Event-Based MNIST datasets...\n",
      "üìä Processing training set to events...\n",
      "üìä Processing training set to events...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to events: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60000/60000 [00:05<00:00, 10252.72it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 60000 samples\n",
      "   Average events per sample: 68.6\n",
      "üìä Processing test set to events...\n",
      "üìä Processing test set to events...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to events: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:00<00:00, 14068.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 10000 samples\n",
      "   Average events per sample: 70.3\n",
      "üì¶ Data loaders created:\n",
      "   Train: 938 batches\n",
      "   Test: 157 batches\n",
      "\n",
      "üìã Sample batch:\n",
      "   Events shape: torch.Size([64, 159])\n",
      "   Features shape: torch.Size([64, 159, 1])\n",
      "   Lengths: tensor([ 40,  73, 159,  67,  79])\n",
      "   Labels: tensor([1, 2, 8, 5, 2])\n",
      "   Events range: [0, 766]\n",
      "   Average sequence length: 76.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# üé≤ EVENT-BASED MNIST DATASET\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import math  # Added missing import\n",
    "\n",
    "# Add the src directory to Python path\n",
    "sys.path.append('/mnt/c/Users/peera/Desktop/KAN-MAMMOTE/src')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our models - Fixed import path\n",
    "from src.models import KAN_MAMMOTE_Model, ImprovedKANMAMOTE\n",
    "from src.utils.config import KANMAMOTEConfig\n",
    "\n",
    "print(\"üì¶ All imports successful!\")\n",
    "print(f\"üîß Using device: {torch.cuda.get_device_name() if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "class EventBasedMNIST(Dataset):\n",
    "    \"\"\"\n",
    "    Convert MNIST images to event-based sequences.\n",
    "    Each non-zero pixel becomes an event with timestamp = pixel position.\n",
    "    Based on EventBasedMNIST_with_log.ipynb implementation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root='./data', train=True, threshold=0.9, transform=None, download=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root: Data directory\n",
    "            train: Training or test set\n",
    "            threshold: Minimum pixel intensity to consider as event\n",
    "            transform: Image transformations\n",
    "            download: Whether to download MNIST\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.threshold = threshold\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load MNIST dataset (following EventBasedMNIST_with_log.ipynb pattern)\n",
    "        if transform is None:\n",
    "            transform = transforms.ToTensor()\n",
    "        \n",
    "        # Fixed: Use full torchvision.datasets path instead of just datasets\n",
    "        self.data = torchvision.datasets.MNIST(\n",
    "            root=self.root, \n",
    "            train=self.train, \n",
    "            transform=transform, \n",
    "            download=download\n",
    "        )\n",
    "        \n",
    "        # Pre-process all images to event sequences\n",
    "        self.event_data = []\n",
    "        self.labels = []\n",
    "        \n",
    "        print(f\"üìä Processing {'training' if train else 'test'} set to events...\")\n",
    "        \n",
    "        for img, label in tqdm(self.data, desc=\"Converting to events\"):\n",
    "            # Flatten image to 1D (784 pixels for 28x28)\n",
    "            img_flat = img.view(-1)  # (784,)\n",
    "            \n",
    "            # Find pixels above threshold (events)\n",
    "            events = torch.nonzero(img_flat > self.threshold).squeeze()\n",
    "            \n",
    "            # Handle edge cases\n",
    "            if events.dim() == 0:  # Single event\n",
    "                events = events.unsqueeze(0)\n",
    "            elif len(events) == 0:  # No events\n",
    "                events = torch.tensor([0])  # Add dummy event\n",
    "                \n",
    "            # Sort events by position (timestamp order)\n",
    "            events = torch.sort(events).values\n",
    "            \n",
    "            self.event_data.append(events)\n",
    "            self.labels.append(label)\n",
    "        \n",
    "        print(f\"‚úÖ Processed {len(self.event_data)} samples\")\n",
    "        print(f\"   Average events per sample: {sum(len(events) for events in self.event_data) / len(self.event_data):.1f}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.event_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        events = self.event_data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Create features based on event positions\n",
    "        # For compatibility with our models, we extract pixel intensities\n",
    "        if len(events) > 0:\n",
    "            # Get original image to extract intensities\n",
    "            original_img, _ = self.data[idx]\n",
    "            img_flat = original_img.view(-1)\n",
    "            \n",
    "            # Extract intensities for the events\n",
    "            intensities = img_flat[events]\n",
    "            features = intensities.unsqueeze(1)  # (seq_len, 1)\n",
    "        else:\n",
    "            # Handle empty case\n",
    "            features = torch.zeros(1, 1)\n",
    "            \n",
    "        return events, features, len(events), label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for variable-length sequences.\n",
    "    Compatible with EventBasedMNIST_with_log.ipynb approach.\n",
    "    \"\"\"\n",
    "    events_list = []\n",
    "    features_list = []\n",
    "    lengths = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for events, features, length, label in batch:\n",
    "        events_list.append(events)\n",
    "        features_list.append(features)\n",
    "        lengths.append(length)\n",
    "        labels_list.append(label)\n",
    "    \n",
    "    # Pad sequences\n",
    "    padded_events = pad_sequence(events_list, batch_first=True, padding_value=0)\n",
    "    padded_features = pad_sequence(features_list, batch_first=True, padding_value=0.0)\n",
    "    \n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    labels = torch.tensor(labels_list, dtype=torch.long)\n",
    "    \n",
    "    return padded_events, padded_features, lengths, labels\n",
    "\n",
    "# Create datasets (matching EventBasedMNIST_with_log.ipynb parameters)\n",
    "print(\"üé≤ Creating Event-Based MNIST datasets...\")\n",
    "train_dataset = EventBasedMNIST(root='./data', train=True, threshold=0.9, download=True)\n",
    "test_dataset = EventBasedMNIST(root='./data', train=False, threshold=0.9, download=True)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"üì¶ Data loaders created:\")\n",
    "print(f\"   Train: {len(train_loader)} batches\")\n",
    "print(f\"   Test: {len(test_loader)} batches\")\n",
    "\n",
    "# Test data loading\n",
    "sample_batch = next(iter(train_loader))\n",
    "events, features, lengths, labels = sample_batch\n",
    "print(f\"\\nüìã Sample batch:\")\n",
    "print(f\"   Events shape: {events.shape}\")\n",
    "print(f\"   Features shape: {features.shape}\")\n",
    "print(f\"   Lengths: {lengths[:5]}\")\n",
    "print(f\"   Labels: {labels[:5]}\")\n",
    "print(f\"   Events range: [{events.min()}, {events.max()}]\")\n",
    "print(f\"   Average sequence length: {lengths.float().mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f12f5b",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Model Definitions\n",
    "\n",
    "We'll define three different LSTM-based models:\n",
    "1. **Baseline LSTM**: Raw timestamps ‚Üí LSTM ‚Üí Classifier\n",
    "2. **LSTM + LETE**: Timestamps ‚Üí LETE ‚Üí LSTM ‚Üí Classifier\n",
    "3. **LSTM + KAN-MAMMOTE**: Timestamps ‚Üí KAN-MAMMOTE ‚Üí LSTM ‚Üí Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf77876f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß STANDARDIZED CONFIGURATION FOR FAIR COMPARISON:\n",
      "   LSTM Hidden Dim: 128\n",
      "   LSTM Layers: 2\n",
      "   LSTM Dropout: 0.2\n",
      "   Time Embedding Dim: 32\n",
      "   Output Classes: 10\n",
      "‚úÖ All models will use identical LSTM architectures!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# üîß STANDARDIZED CONFIGURATION FOR FAIR COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "import math\n",
    "\n",
    "# Standard configuration for all models\n",
    "STANDARD_CONFIG = {\n",
    "    'lstm_hidden_dim': 128,     # Same LSTM hidden dimension for all models\n",
    "    'lstm_num_layers': 2,       # Same LSTM layers for all models\n",
    "    'lstm_dropout': 0.2,        # Same LSTM dropout for all models\n",
    "    'time_emb_dim': 32,         # Standardized time embedding dimension\n",
    "    'num_classes': 10           # MNIST classes\n",
    "}\n",
    "\n",
    "print(\"üîß STANDARDIZED CONFIGURATION FOR FAIR COMPARISON:\")\n",
    "print(f\"   LSTM Hidden Dim: {STANDARD_CONFIG['lstm_hidden_dim']}\")\n",
    "print(f\"   LSTM Layers: {STANDARD_CONFIG['lstm_num_layers']}\")\n",
    "print(f\"   LSTM Dropout: {STANDARD_CONFIG['lstm_dropout']}\")\n",
    "print(f\"   Time Embedding Dim: {STANDARD_CONFIG['time_emb_dim']}\")\n",
    "print(f\"   Output Classes: {STANDARD_CONFIG['num_classes']}\")\n",
    "print(\"‚úÖ All models will use identical LSTM architectures!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c8a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Creating standardized models with identical LSTM architectures...\n",
      "‚úÖ LETE embedding initialized successfully with standardized dimension\n",
      "‚úì Using FasterKANLayer: 32‚Üí32, grids=5\n",
      "\n",
      "üìä STANDARDIZED Model Parameter Comparison:\n",
      "   Baseline LSTM:        200,970 parameters\n",
      "   LSTM + SinCos:        232,778 parameters\n",
      "   LSTM + LETE:          221,370 parameters\n",
      "   LSTM + KAN-MAMMOTE:   255,698 parameters\n",
      "\n",
      "üîç Parameter Breakdown:\n",
      "   LSTM layers (all models): ~263,168 parameters\n",
      "   Classifier (all models):  ~1,290 parameters\n",
      "   Time embedding differences:\n",
      "     - Baseline: Simple concatenation (no extra parameters)\n",
      "     - SinCos: Fixed embeddings (no learnable parameters)\n",
      "     - LETE: Learnable time embedding (~-43,088 parameters)\n",
      "     - KAN-MAMMOTE: Complex embedding (~-8,760 parameters)\n",
      "\n",
      "üß™ Testing all standardized models...\n",
      "‚úÖ LETE embedding initialized successfully with standardized dimension\n",
      "‚úì Using FasterKANLayer: 32‚Üí32, grids=5\n",
      "\n",
      "üìä STANDARDIZED Model Parameter Comparison:\n",
      "   Baseline LSTM:        200,970 parameters\n",
      "   LSTM + SinCos:        232,778 parameters\n",
      "   LSTM + LETE:          221,370 parameters\n",
      "   LSTM + KAN-MAMMOTE:   255,698 parameters\n",
      "\n",
      "üîç Parameter Breakdown:\n",
      "   LSTM layers (all models): ~263,168 parameters\n",
      "   Classifier (all models):  ~1,290 parameters\n",
      "   Time embedding differences:\n",
      "     - Baseline: Simple concatenation (no extra parameters)\n",
      "     - SinCos: Fixed embeddings (no learnable parameters)\n",
      "     - LETE: Learnable time embedding (~-43,088 parameters)\n",
      "     - KAN-MAMMOTE: Complex embedding (~-8,760 parameters)\n",
      "\n",
      "üß™ Testing all standardized models...\n",
      "   ‚úÖ Baseline LSTM: Output shape torch.Size([2, 10]), Range [-0.101, 0.086]\n",
      "   ‚úÖ LSTM + SinCos: Output shape torch.Size([2, 10]), Range [-0.006, 0.007]\n",
      "   ‚úÖ Baseline LSTM: Output shape torch.Size([2, 10]), Range [-0.101, 0.086]\n",
      "   ‚úÖ LSTM + SinCos: Output shape torch.Size([2, 10]), Range [-0.006, 0.007]\n",
      "   ‚úÖ LSTM + LETE: Output shape torch.Size([2, 10]), Range [-0.079, 0.122]\n",
      "   ‚úÖ LSTM + KAN-MAMMOTE: Output shape torch.Size([2, 10]), Range [-0.095, 0.086]\n",
      "\n",
      "üéØ STANDARDIZATION COMPLETE!\n",
      "‚úÖ All models now have identical LSTM architectures:\n",
      "   - LSTM Hidden Dim: 128\n",
      "   - LSTM Layers: 2\n",
      "   - Time Embedding Dim: 32\n",
      "   - Dropout: 0.2\n",
      "‚úÖ Performance differences will now purely reflect embedding effectiveness!\n",
      "   ‚úÖ LSTM + LETE: Output shape torch.Size([2, 10]), Range [-0.079, 0.122]\n",
      "   ‚úÖ LSTM + KAN-MAMMOTE: Output shape torch.Size([2, 10]), Range [-0.095, 0.086]\n",
      "\n",
      "üéØ STANDARDIZATION COMPLETE!\n",
      "‚úÖ All models now have identical LSTM architectures:\n",
      "   - LSTM Hidden Dim: 128\n",
      "   - LSTM Layers: 2\n",
      "   - Time Embedding Dim: 32\n",
      "   - Dropout: 0.2\n",
      "‚úÖ Performance differences will now purely reflect embedding effectiveness!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# üéØ MODEL 1: BASELINE LSTM (STANDARDIZED)\n",
    "# ============================================================================\n",
    "\n",
    "class StandardizedBaselineLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    STANDARDIZED Baseline LSTM model with simple temporal information.\n",
    "    Uses the same LSTM architecture as all other models for fair comparison.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config=STANDARD_CONFIG):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Input: [normalized_timestamp, pixel_intensity] = 2 dimensions\n",
    "        input_dim = 2\n",
    "        \n",
    "        # STANDARDIZED LSTM (identical to all other models)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=config['lstm_hidden_dim'],\n",
    "            num_layers=config['lstm_num_layers'],\n",
    "            batch_first=True,\n",
    "            dropout=config['lstm_dropout']\n",
    "        )\n",
    "        \n",
    "        # STANDARDIZED classifier\n",
    "        self.classifier = nn.Linear(config['lstm_hidden_dim'], config['num_classes'])\n",
    "        \n",
    "    def forward(self, events, features, lengths):\n",
    "        # Combine timestamps and features\n",
    "        # events: (batch, seq_len) - timestamps\n",
    "        # features: (batch, seq_len, 1) - pixel intensities\n",
    "        \n",
    "        # Normalize timestamps to [0, 1] range\n",
    "        timestamps_normalized = (events.float() / 783.0).unsqueeze(-1)  # (batch, seq_len, 1)\n",
    "        \n",
    "        # Combine timestamp and pixel intensity\n",
    "        combined_input = torch.cat([timestamps_normalized, features], dim=-1)  # (batch, seq_len, 2)\n",
    "        \n",
    "        # Pack sequences for LSTM\n",
    "        packed = pack_padded_sequence(combined_input, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # STANDARDIZED LSTM forward pass\n",
    "        lstm_out, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        # Use last hidden state for classification\n",
    "        final_hidden = h_n[-1]  # (batch, lstm_hidden_dim)\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(final_hidden)\n",
    "        return logits\n",
    "\n",
    "# ============================================================================\n",
    "# üåü MODEL 2: LSTM + SinCos (STANDARDIZED)\n",
    "# ============================================================================\n",
    "\n",
    "class StandardizedSinCosEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    STANDARDIZED SinCos embedding with consistent dimensions.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model=32, max_len=784):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Create FIXED sinusoidal embeddings (non-learnable)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # Register as buffer (not parameter) - fixed embeddings\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, timestamps):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            timestamps: (batch, seq_len) - pixel positions [0, 783]\n",
    "        Returns:\n",
    "            time_emb: (batch, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = timestamps.shape\n",
    "        \n",
    "        # Normalize pixel positions to valid range [0, 783]\n",
    "        timestamps_norm = torch.clamp(timestamps.long(), 0, 783)\n",
    "        \n",
    "        # Get fixed sinusoidal embeddings\n",
    "        time_emb = self.pe[timestamps_norm]  # (batch, seq_len, d_model)\n",
    "        \n",
    "        return time_emb\n",
    "\n",
    "class StandardizedLSTM_SinCos(nn.Module):\n",
    "    \"\"\"STANDARDIZED LSTM model with SinCos time embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, config=STANDARD_CONFIG):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # STANDARDIZED SinCos time embedding\n",
    "        self.time_embedding = StandardizedSinCosEmbedding(d_model=config['time_emb_dim'])\n",
    "        \n",
    "        # Feature processing (project to match time embedding dimension)\n",
    "        self.feature_projection = nn.Linear(1, config['time_emb_dim'])\n",
    "        \n",
    "        # STANDARDIZED LSTM (identical to all other models)\n",
    "        lstm_input_dim = config['time_emb_dim'] + config['time_emb_dim']  # time_emb + feature_proj\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_dim,\n",
    "            hidden_size=config['lstm_hidden_dim'],\n",
    "            num_layers=config['lstm_num_layers'],\n",
    "            batch_first=True,\n",
    "            dropout=config['lstm_dropout']\n",
    "        )\n",
    "        \n",
    "        # STANDARDIZED classifier\n",
    "        self.classifier = nn.Linear(config['lstm_hidden_dim'], config['num_classes'])\n",
    "        \n",
    "        # Conservative weight initialization\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Conservative weight initialization to prevent gradient issues.\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight, gain=0.5)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.LSTM):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if 'weight' in name:\n",
    "                        nn.init.xavier_uniform_(param, gain=0.5)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.zeros_(param)\n",
    "        \n",
    "    def forward(self, events, features, lengths):\n",
    "        # Get STANDARDIZED SinCos time embeddings\n",
    "        time_emb = self.time_embedding(events)  # (batch, seq_len, time_emb_dim)\n",
    "        \n",
    "        # Process features to match time embedding dimension\n",
    "        feature_emb = self.feature_projection(features)  # (batch, seq_len, time_emb_dim)\n",
    "        \n",
    "        # Combine embeddings\n",
    "        combined = torch.cat([time_emb, feature_emb], dim=-1)  # (batch, seq_len, 2*time_emb_dim)\n",
    "        \n",
    "        # Pack sequences for LSTM\n",
    "        packed = pack_padded_sequence(combined, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # STANDARDIZED LSTM forward pass\n",
    "        lstm_out, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        # Use last hidden state for classification\n",
    "        final_hidden = h_n[-1]  # (batch, lstm_hidden_dim)\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(final_hidden)\n",
    "        return logits\n",
    "\n",
    "# ============================================================================\n",
    "# üî• MODEL 3: LSTM + LETE (STANDARDIZED)\n",
    "# ============================================================================\n",
    "\n",
    "class StandardizedLSTM_LETE(nn.Module):\n",
    "    \"\"\"\n",
    "    STANDARDIZED LSTM model with LETE time embedding.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config=STANDARD_CONFIG):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Initialize LETE with STANDARDIZED embedding dimension\n",
    "        self.use_lete = False\n",
    "        try:\n",
    "            # Use STANDARDIZED time embedding dimension\n",
    "            self.time_encoder = CombinedLeTE(config['time_emb_dim'], p=0.5)\n",
    "            \n",
    "            # Test LETE with dummy data\n",
    "            dummy_input = torch.randn(1, 5).abs().clamp(0, 783)\n",
    "            with torch.no_grad():\n",
    "                test_emb = self.time_encoder(dummy_input)\n",
    "                if torch.isnan(test_emb).any() or torch.isinf(test_emb).any():\n",
    "                    raise ValueError(\"LETE produces NaN/Inf on test input\")\n",
    "            \n",
    "            self.use_lete = True\n",
    "            print(\"‚úÖ LETE embedding initialized successfully with standardized dimension\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå LETE initialization failed: {e}\")\n",
    "            # Fallback to simple embedding\n",
    "            self.time_encoder = nn.Embedding(784, config['time_emb_dim'])\n",
    "            self.use_lete = False\n",
    "            print(\"‚ö†Ô∏è Using simple embedding as fallback\")\n",
    "        \n",
    "        # STANDARDIZED LSTM (identical to all other models)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=config['time_emb_dim'],\n",
    "            hidden_size=config['lstm_hidden_dim'],\n",
    "            num_layers=config['lstm_num_layers'],\n",
    "            batch_first=True,\n",
    "            dropout=config['lstm_dropout']\n",
    "        )\n",
    "        \n",
    "        # STANDARDIZED classifier\n",
    "        self.classifier = nn.Linear(config['lstm_hidden_dim'], config['num_classes'])\n",
    "        \n",
    "    def forward(self, events, features, lengths):\n",
    "        batch_size = events.size(0)\n",
    "        \n",
    "        if self.use_lete:\n",
    "            # Use LETE with proper input handling\n",
    "            events_float = events.float()\n",
    "            \n",
    "            try:\n",
    "                # Apply LETE time encoding\n",
    "                embedded = self.time_encoder(events_float)  # (batch, seq_len, time_emb_dim)\n",
    "                \n",
    "                # Check for NaN/Inf\n",
    "                if torch.isnan(embedded).any() or torch.isinf(embedded).any():\n",
    "                    print(\"‚ö†Ô∏è LETE produced NaN/Inf, using zero embedding\")\n",
    "                    embedded = torch.zeros(batch_size, events.size(1), self.config['time_emb_dim'], device=events.device)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è LETE forward failed: {e}, using zero embedding\")\n",
    "                embedded = torch.zeros(batch_size, events.size(1), self.config['time_emb_dim'], device=events.device)\n",
    "        else:\n",
    "            # Use simple embedding fallback\n",
    "            events_clamped = torch.clamp(events.long(), 0, 783)\n",
    "            embedded = self.time_encoder(events_clamped)\n",
    "        \n",
    "        # Pack sequences for LSTM\n",
    "        packed = pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # STANDARDIZED LSTM forward pass\n",
    "        _, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        # Use last hidden state for classification\n",
    "        final_hidden = h_n[-1]  # (batch, lstm_hidden_dim)\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(final_hidden)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# ============================================================================\n",
    "# üöÄ MODEL 4: LSTM + KAN-MAMMOTE (STANDARDIZED)\n",
    "# ============================================================================\n",
    "\n",
    "class StandardizedLSTM_KAN_MAMMOTE(nn.Module):\n",
    "    \"\"\"\n",
    "    STANDARDIZED LSTM model with KAN-MAMMOTE time embedding.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config=STANDARD_CONFIG):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # KAN-MAMMOTE configuration with STANDARDIZED output dimension\n",
    "        self.kan_config = KANMAMOTEConfig(\n",
    "            D_time=config['time_emb_dim'],  # STANDARDIZED time embedding dimension\n",
    "            num_experts=4,\n",
    "            hidden_dim_mamba=config['time_emb_dim'],  # Match time embedding dimension\n",
    "            state_dim_mamba=16,  # Smaller state dimension\n",
    "            num_mamba_layers=2,\n",
    "            gamma=0.3,\n",
    "            use_aux_features_router=False,\n",
    "            raw_event_feature_dim=0,\n",
    "            K_top=2,\n",
    "            # Faster-KAN parameters\n",
    "            kan_grid_size=5,\n",
    "            kan_grid_min=-2.0,\n",
    "            kan_grid_max=2.0,\n",
    "            kan_spline_scale=0.667,\n",
    "            kan_num_layers=2,\n",
    "            kan_hidden_dim=config['time_emb_dim']\n",
    "        )\n",
    "        \n",
    "        # KAN-MAMMOTE for time embedding\n",
    "        self.kan_mammote = ImprovedKANMAMOTE(self.kan_config)\n",
    "        \n",
    "        # Feature projection to match time embedding dimension\n",
    "        self.feature_projection = nn.Linear(1, config['time_emb_dim'])\n",
    "        \n",
    "        # STANDARDIZED LSTM (identical to all other models)\n",
    "        lstm_input_dim = config['time_emb_dim'] + config['time_emb_dim']  # kan_emb + feature_proj\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_dim,\n",
    "            hidden_size=config['lstm_hidden_dim'],\n",
    "            num_layers=config['lstm_num_layers'],\n",
    "            batch_first=True,\n",
    "            dropout=config['lstm_dropout']\n",
    "        )\n",
    "        \n",
    "        # STANDARDIZED classifier\n",
    "        self.classifier = nn.Linear(config['lstm_hidden_dim'], config['num_classes'])\n",
    "        \n",
    "    def forward(self, events, features, lengths):\n",
    "        batch_size = events.size(0)\n",
    "        \n",
    "        # Normalize timestamps to [0, 1] range for KAN-MAMMOTE\n",
    "        timestamps = events.float() / 783.0\n",
    "        timestamps = timestamps.unsqueeze(-1)  # (batch, seq_len, 1)\n",
    "        \n",
    "        # Empty features for KAN-MAMMOTE\n",
    "        empty_features = torch.zeros(batch_size, timestamps.size(1), 0, device=timestamps.device)\n",
    "        \n",
    "        # Apply KAN-MAMMOTE embedding\n",
    "        try:\n",
    "            kan_emb, kan_info = self.kan_mammote(timestamps, empty_features)\n",
    "            # kan_emb: (batch, seq_len, time_emb_dim)\n",
    "        except Exception as e:\n",
    "            print(f\"KAN-MAMMOTE error: {e}\")\n",
    "            # Fallback: create embeddings with correct dimension\n",
    "            kan_emb = torch.zeros(batch_size, timestamps.size(1), self.config['time_emb_dim'], device=timestamps.device)\n",
    "            kan_info = {}\n",
    "        \n",
    "        # Project pixel features to match time embedding dimension\n",
    "        feature_emb = self.feature_projection(features)  # (batch, seq_len, time_emb_dim)\n",
    "        \n",
    "        # Combine embeddings\n",
    "        combined = torch.cat([kan_emb, feature_emb], dim=-1)  # (batch, seq_len, 2*time_emb_dim)\n",
    "        \n",
    "        # Pack sequences for LSTM\n",
    "        packed = pack_padded_sequence(combined, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # STANDARDIZED LSTM forward pass\n",
    "        lstm_out, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        # Use last hidden state for classification\n",
    "        final_hidden = h_n[-1]  # (batch, lstm_hidden_dim)\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(final_hidden)\n",
    "        \n",
    "        return logits, kan_info\n",
    "\n",
    "# ============================================================================\n",
    "# üèóÔ∏è CREATE STANDARDIZED MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üèóÔ∏è Creating standardized models with identical LSTM architectures...\")\n",
    "\n",
    "# Create all models with standardized configuration\n",
    "baseline_model = StandardizedBaselineLSTM(STANDARD_CONFIG).to(device)\n",
    "sincos_model = StandardizedLSTM_SinCos(STANDARD_CONFIG).to(device)\n",
    "lete_model = StandardizedLSTM_LETE(STANDARD_CONFIG).to(device)\n",
    "kan_model = StandardizedLSTM_KAN_MAMMOTE(STANDARD_CONFIG).to(device)\n",
    "\n",
    "# Calculate parameters\n",
    "baseline_params = sum(p.numel() for p in baseline_model.parameters() if p.requires_grad)\n",
    "sincos_params = sum(p.numel() for p in sincos_model.parameters() if p.requires_grad)\n",
    "lete_params = sum(p.numel() for p in lete_model.parameters() if p.requires_grad)\n",
    "kan_params = sum(p.numel() for p in kan_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nüìä STANDARDIZED Model Parameter Comparison:\")\n",
    "print(f\"   Baseline LSTM:        {baseline_params:,} parameters\")\n",
    "print(f\"   LSTM + SinCos:        {sincos_params:,} parameters\")\n",
    "print(f\"   LSTM + LETE:          {lete_params:,} parameters\")\n",
    "print(f\"   LSTM + KAN-MAMMOTE:   {kan_params:,} parameters\")\n",
    "\n",
    "# Calculate LSTM-only parameters for comparison\n",
    "lstm_only_params = (STANDARD_CONFIG['lstm_hidden_dim'] * 2 + 1) * STANDARD_CONFIG['lstm_hidden_dim'] * 4 * STANDARD_CONFIG['lstm_num_layers']\n",
    "classifier_params = STANDARD_CONFIG['lstm_hidden_dim'] * STANDARD_CONFIG['num_classes'] + STANDARD_CONFIG['num_classes']\n",
    "\n",
    "print(f\"\\nüîç Parameter Breakdown:\")\n",
    "print(f\"   LSTM layers (all models): ~{lstm_only_params:,} parameters\")\n",
    "print(f\"   Classifier (all models):  ~{classifier_params:,} parameters\")\n",
    "print(f\"   Time embedding differences:\")\n",
    "print(f\"     - Baseline: Simple concatenation (no extra parameters)\")\n",
    "print(f\"     - SinCos: Fixed embeddings (no learnable parameters)\")\n",
    "print(f\"     - LETE: Learnable time embedding (~{lete_params - lstm_only_params - classifier_params:,} parameters)\")\n",
    "print(f\"     - KAN-MAMMOTE: Complex embedding (~{kan_params - lstm_only_params - classifier_params:,} parameters)\")\n",
    "\n",
    "# Test all models\n",
    "print(f\"\\nüß™ Testing all standardized models...\")\n",
    "test_events = torch.randint(0, 784, (2, 10)).to(device)\n",
    "test_features = torch.randn(2, 10, 1).to(device)\n",
    "test_lengths = torch.tensor([10, 8]).to(device)\n",
    "\n",
    "models_to_test = [\n",
    "    (baseline_model, \"Baseline LSTM\"),\n",
    "    (sincos_model, \"LSTM + SinCos\"),\n",
    "    (lete_model, \"LSTM + LETE\"),\n",
    "    (kan_model, \"LSTM + KAN-MAMMOTE\")\n",
    "]\n",
    "\n",
    "for model, name in models_to_test:\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            if 'KAN' in name:\n",
    "                test_output, _ = model(test_events, test_features, test_lengths)\n",
    "            else:\n",
    "                test_output = model(test_events, test_features, test_lengths)\n",
    "            \n",
    "            print(f\"   ‚úÖ {name}: Output shape {test_output.shape}, Range [{test_output.min():.3f}, {test_output.max():.3f}]\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå {name}: Test failed - {e}\")\n",
    "\n",
    "print(f\"\\nüéØ STANDARDIZATION COMPLETE!\")\n",
    "print(f\"‚úÖ All models now have identical LSTM architectures:\")\n",
    "print(f\"   - LSTM Hidden Dim: {STANDARD_CONFIG['lstm_hidden_dim']}\")\n",
    "print(f\"   - LSTM Layers: {STANDARD_CONFIG['lstm_num_layers']}\")\n",
    "print(f\"   - Time Embedding Dim: {STANDARD_CONFIG['time_emb_dim']}\")\n",
    "print(f\"   - Dropout: {STANDARD_CONFIG['lstm_dropout']}\")\n",
    "print(f\"‚úÖ Performance differences will now purely reflect embedding effectiveness!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9184ac",
   "metadata": {},
   "source": [
    "## üéØ Training Setup\n",
    "\n",
    "Define training and evaluation functions that work for all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd69ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training functions ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# üèãÔ∏è TRAINING AND EVALUATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_model(model, train_loader, test_loader, model_name, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Train a model and track performance metrics.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüèãÔ∏è Training {model_name}...\")\n",
    "    \n",
    "    # Setup optimizer and loss\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Tracking metrics\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    epoch_times = []\n",
    "    \n",
    "    best_test_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # ========== TRAINING PHASE ==========\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_bar = tqdm(train_loader, desc=f\"{model_name} Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        for batch_idx, (events, features, lengths, labels) in enumerate(train_bar):\n",
    "            events, features, lengths, labels = events.to(device), features.to(device), lengths.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass (handle KAN-MAMMOTE returning additional info)\n",
    "            if 'KAN' in model_name:\n",
    "                outputs, _ = model(events, features, lengths)\n",
    "            else:\n",
    "                outputs = model(events, features, lengths)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            train_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100.*train_correct/train_total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # ========== EVALUATION PHASE ==========\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for events, features, lengths, labels in test_loader:\n",
    "                events, features, lengths, labels = events.to(device), features.to(device), lengths.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                if 'KAN' in model_name:\n",
    "                    outputs, _ = model(events, features, lengths)\n",
    "                else:\n",
    "                    outputs = model(events, features, lengths)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                test_loss += loss.item() * labels.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_loss = train_loss / train_total\n",
    "        train_acc = 100. * train_correct / train_total\n",
    "        test_loss = test_loss / test_total\n",
    "        test_acc = 100. * test_correct / test_total\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(test_loss)\n",
    "        \n",
    "        # Record metrics\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "        epoch_times.append(epoch_time)\n",
    "        \n",
    "        # Track best model\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "        print(f\"  Time: {epoch_time:.1f}s, Best Acc: {best_test_acc:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'test_losses': test_losses,\n",
    "        'test_accs': test_accs,\n",
    "        'epoch_times': epoch_times,\n",
    "        'best_test_acc': best_test_acc,\n",
    "        'final_test_acc': test_accs[-1],\n",
    "        'avg_epoch_time': np.mean(epoch_times)\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Training functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500bafff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ IMPROVED K-MOTE regularization ready!\n",
      "üéØ Key improvements:\n",
      "   ‚Ä¢ Both TV and Sobolev applied consistently to ALL K-MOTE experts\n",
      "   ‚Ä¢ No regularization of output embeddings (preserves diversity)\n",
      "   ‚Ä¢ Expert diversity encourages balanced usage\n",
      "   ‚Ä¢ Temporal expert consistency for smooth transitions\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# üöÄ IMPROVED K-MOTE REGULARIZATION - CONSISTENT TV + SOBOLEV FOR ALL EXPERTS\n",
    "# ============================================================================\n",
    "\n",
    "def compute_improved_kmote_regularizers(kan_mammote, timestamps, kan_info, device):\n",
    "    \"\"\"\n",
    "    IMPROVED: Apply both TV and Sobolev regularizers to ALL K-MOTE experts consistently.\n",
    "    Target the internal expert functions, not the output embeddings.\n",
    "    \"\"\"\n",
    "    regularizers = {}\n",
    "    total_reg = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 1. EXPERT FUNCTION REGULARIZATION - Apply to ALL K-MOTE experts\n",
    "    # ============================================================================\n",
    "    tv_loss = torch.tensor(0.0, device=device)\n",
    "    sobolev_loss = torch.tensor(0.0, device=device)\n",
    "    expert_count = 0\n",
    "    \n",
    "    try:\n",
    "        # Target K-MOTE expert modules\n",
    "        for name, module in kan_mammote.named_modules():\n",
    "            expert_params = None\n",
    "            expert_type = None\n",
    "            \n",
    "            # 1. Spline Expert (Faster-KAN)\n",
    "            if hasattr(module, 'spline_weight') and module.spline_weight is not None:\n",
    "                expert_params = module.spline_weight\n",
    "                expert_type = \"spline\"\n",
    "            \n",
    "            # 2. Fourier Expert (if it has learnable coefficients)\n",
    "            elif hasattr(module, 'fourier_coeffs') and module.fourier_coeffs is not None:\n",
    "                expert_params = module.fourier_coeffs\n",
    "                expert_type = \"fourier\"\n",
    "            \n",
    "            # 3. Wavelet Expert (if it has learnable coefficients)\n",
    "            elif hasattr(module, 'wavelet_coeffs') and module.wavelet_coeffs is not None:\n",
    "                expert_params = module.wavelet_coeffs\n",
    "                expert_type = \"wavelet\"\n",
    "            \n",
    "            # 4. RKHS Expert (if it has learnable parameters)\n",
    "            elif hasattr(module, 'rkhs_weights') and module.rkhs_weights is not None:\n",
    "                expert_params = module.rkhs_weights\n",
    "                expert_type = \"rkhs\"\n",
    "            \n",
    "            # 5. General learnable parameters in expert modules\n",
    "            elif 'expert' in name.lower() and hasattr(module, 'weight') and module.weight is not None:\n",
    "                expert_params = module.weight\n",
    "                expert_type = \"general\"\n",
    "            \n",
    "            # 6. KAN layer weights (catch-all for KAN components)\n",
    "            elif hasattr(module, 'weight') and module.weight is not None and 'kan' in name.lower():\n",
    "                expert_params = module.weight\n",
    "                expert_type = \"kan_layer\"\n",
    "            \n",
    "            # Apply regularization to found expert parameters\n",
    "            if expert_params is not None and expert_params.numel() > 2:\n",
    "                # Ensure we have the right dimensions for regularization\n",
    "                if expert_params.dim() >= 2:\n",
    "                    # Flatten to 2D: (num_functions, function_length)\n",
    "                    params_2d = expert_params.view(-1, expert_params.size(-1))\n",
    "                    \n",
    "                    # TOTAL VARIATION (TV) - Penalize oscillations in expert functions\n",
    "                    if params_2d.size(-1) > 1:\n",
    "                        tv_diff = params_2d[:, 1:] - params_2d[:, :-1]\n",
    "                        tv_loss += torch.sum(torch.abs(tv_diff))\n",
    "                    \n",
    "                    # SOBOLEV - Penalize curvature (second derivative) in expert functions\n",
    "                    if params_2d.size(-1) > 2:\n",
    "                        first_diff = params_2d[:, 1:] - params_2d[:, :-1]\n",
    "                        if first_diff.size(-1) > 1:\n",
    "                            second_diff = first_diff[:, 1:] - first_diff[:, :-1]\n",
    "                            sobolev_loss += torch.sum(second_diff ** 2)\n",
    "                    \n",
    "                    expert_count += 1\n",
    "                    if expert_count <= 3:  # Only print first few to avoid spam\n",
    "                        print(f\"   ‚úÖ Regularizing {expert_type} expert: {expert_params.shape}\")\n",
    "        \n",
    "        # Normalize by number of experts to keep scale consistent\n",
    "        if expert_count > 0:\n",
    "            tv_loss = tv_loss / expert_count\n",
    "            sobolev_loss = sobolev_loss / expert_count\n",
    "            \n",
    "        regularizers['tv'] = tv_loss\n",
    "        regularizers['sobolev'] = sobolev_loss\n",
    "        total_reg += 1e-4 * tv_loss + 1e-5 * sobolev_loss\n",
    "        \n",
    "        print(f\"   üìä Applied TV+Sobolev to {expert_count} K-MOTE expert functions\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Expert regularization failed: {e}\")\n",
    "        regularizers['tv'] = torch.tensor(0.0, device=device)\n",
    "        regularizers['sobolev'] = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 2. EXPERT DIVERSITY REGULARIZATION - Balanced expert usage\n",
    "    # ============================================================================\n",
    "    diversity_loss = torch.tensor(0.0, device=device)\n",
    "    try:\n",
    "        if 'kmote_info' in kan_info and 'expert_weights' in kan_info['kmote_info']:\n",
    "            expert_weights = kan_info['kmote_info']['expert_weights']\n",
    "            expert_probs = torch.softmax(expert_weights, dim=-1)\n",
    "            \n",
    "            # Encourage uniform expert usage (entropy maximization)\n",
    "            avg_expert_usage = expert_probs.mean(dim=(0, 1))\n",
    "            num_experts = avg_expert_usage.size(0)\n",
    "            uniform_target = torch.ones_like(avg_expert_usage) / num_experts\n",
    "            \n",
    "            # KL divergence from uniform distribution\n",
    "            diversity_loss = F.kl_div(\n",
    "                torch.log(avg_expert_usage + 1e-8),\n",
    "                uniform_target,\n",
    "                reduction='sum'\n",
    "            )\n",
    "            \n",
    "        regularizers['diversity'] = diversity_loss\n",
    "        total_reg += 1e-3 * diversity_loss\n",
    "        \n",
    "    except Exception as e:\n",
    "        regularizers['diversity'] = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 3. TEMPORAL EXPERT CONSISTENCY - Smooth expert transitions\n",
    "    # ============================================================================\n",
    "    temporal_expert_loss = torch.tensor(0.0, device=device)\n",
    "    try:\n",
    "        if 'kmote_info' in kan_info and 'expert_weights' in kan_info['kmote_info']:\n",
    "            expert_weights = kan_info['kmote_info']['expert_weights']  # (batch, seq, experts)\n",
    "            \n",
    "            # Penalize rapid changes in expert selection over time\n",
    "            if expert_weights.size(1) > 1:\n",
    "                expert_weight_diffs = expert_weights[:, 1:] - expert_weights[:, :-1]\n",
    "                temporal_expert_loss = torch.mean(torch.sum(torch.abs(expert_weight_diffs), dim=-1))\n",
    "        \n",
    "        regularizers['temporal_expert'] = temporal_expert_loss\n",
    "        total_reg += 1e-4 * temporal_expert_loss\n",
    "        \n",
    "    except Exception as e:\n",
    "        regularizers['temporal_expert'] = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 4. EMBEDDING MAGNITUDE CONTROL - Prevent explosive growth\n",
    "    # ============================================================================\n",
    "    magnitude_loss = torch.tensor(0.0, device=device)\n",
    "    try:\n",
    "        if 'temporal_differences' in kan_info:\n",
    "            temporal_diffs = kan_info['temporal_differences']\n",
    "            # L2 penalty on embedding magnitudes (not differences!)\n",
    "            magnitude_loss = torch.mean(torch.norm(temporal_diffs, dim=-1) ** 2)\n",
    "        \n",
    "        regularizers['magnitude'] = magnitude_loss\n",
    "        total_reg += 1e-6 * magnitude_loss  # Very small coefficient\n",
    "        \n",
    "    except Exception as e:\n",
    "        regularizers['magnitude'] = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    return total_reg, regularizers\n",
    "\n",
    "def train_model_improved_kan_mammote(model, train_loader, test_loader, model_name, num_epochs=10):\n",
    "    \"\"\"\n",
    "    IMPROVED: Enhanced training with consistent regularization for all K-MOTE experts.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüöÄ IMPROVED KAN-MAMMOTE Training with Consistent Regularization...\")\n",
    "    print(f\"   üéØ TV + Sobolev: Applied to ALL K-MOTE expert functions\")\n",
    "    print(f\"   üéØ Expert Diversity: Balanced usage of all experts\")\n",
    "    print(f\"   üéØ Temporal Consistency: Smooth expert transitions\")\n",
    "    print(f\"   üéØ Magnitude Control: Prevent embedding explosion\")\n",
    "    \n",
    "    # Enhanced optimizer setup\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4, betas=(0.9, 0.999))\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Tracking metrics including regularization\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    epoch_times = []\n",
    "    regularization_history = {\n",
    "        'total': [], 'tv': [], 'sobolev': [], 'diversity': [], \n",
    "        'temporal_expert': [], 'magnitude': []\n",
    "    }\n",
    "    \n",
    "    best_test_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    early_stop_patience = 8\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # ========== TRAINING PHASE ==========\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        epoch_reg_losses = {key: 0.0 for key in regularization_history.keys()}\n",
    "        \n",
    "        train_bar = tqdm(train_loader, desc=f\"üöÄ {model_name} Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        for batch_idx, (events, features, lengths, labels) in enumerate(train_bar):\n",
    "            events, features, lengths, labels = events.to(device), features.to(device), lengths.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with KAN-MAMMOTE info\n",
    "            outputs, kan_info = model(events, features, lengths)\n",
    "            \n",
    "            # Standard classification loss\n",
    "            classification_loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Compute IMPROVED K-MOTE regularizers\n",
    "            reg_loss, reg_components = compute_improved_kmote_regularizers(\n",
    "                model.kan_mammote, events, kan_info, device\n",
    "            )\n",
    "            \n",
    "            # Total loss with regularization\n",
    "            total_loss = classification_loss + reg_loss\n",
    "            \n",
    "            # Backward pass with gradient clipping\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            train_loss += classification_loss.item() * labels.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Track regularization components\n",
    "            epoch_reg_losses['total'] += reg_loss.item()\n",
    "            for key, value in reg_components.items():\n",
    "                if key in epoch_reg_losses:\n",
    "                    epoch_reg_losses[key] += value.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_bar.set_postfix({\n",
    "                'Loss': f'{classification_loss.item():.4f}',\n",
    "                'Reg': f'{reg_loss.item():.6f}',\n",
    "                'Acc': f'{100.*train_correct/train_total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # ========== EVALUATION PHASE ==========\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for events, features, lengths, labels in test_loader:\n",
    "                events, features, lengths, labels = events.to(device), features.to(device), lengths.to(device), labels.to(device)\n",
    "                \n",
    "                outputs, _ = model(events, features, lengths)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                test_loss += loss.item() * labels.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_loss = train_loss / train_total\n",
    "        train_acc = 100. * train_correct / train_total\n",
    "        test_loss = test_loss / test_total\n",
    "        test_acc = 100. * test_correct / test_total\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Record metrics\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "        epoch_times.append(epoch_time)\n",
    "        \n",
    "        # Record regularization\n",
    "        for key in regularization_history.keys():\n",
    "            regularization_history[key].append(epoch_reg_losses[key] / len(train_loader))\n",
    "        \n",
    "        # Early stopping and best model tracking\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        '''print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "        print(f\"  Regularization - Total: {epoch_reg_losses['total']/len(train_loader):.6f}\")\n",
    "        print(f\"    TV: {epoch_reg_losses['tv']/len(train_loader):.6f}, Sobolev: {epoch_reg_losses['sobolev']/len(train_loader):.6f}\")\n",
    "        print(f\"    Diversity: {epoch_reg_losses['diversity']/len(train_loader):.6f}\")\n",
    "        print(f\"  Time: {epoch_time:.1f}s, Best Acc: {best_test_acc:.2f}%\")\n",
    "        print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")'''\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(f\"üõë Early stopping after {epoch+1} epochs (no improvement for {patience_counter} epochs)\")\n",
    "            break\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'test_losses': test_losses,\n",
    "        'test_accs': test_accs,\n",
    "        'epoch_times': epoch_times,\n",
    "        'regularization_history': regularization_history,\n",
    "        'best_test_acc': best_test_acc,\n",
    "        'final_test_acc': test_accs[-1],\n",
    "        'avg_epoch_time': np.mean(epoch_times)\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ IMPROVED K-MOTE regularization ready!\")\n",
    "print(\"üéØ Key improvements:\")\n",
    "print(\"   ‚Ä¢ Both TV and Sobolev applied consistently to ALL K-MOTE experts\")\n",
    "print(\"   ‚Ä¢ No regularization of output embeddings (preserves diversity)\")\n",
    "print(\"   ‚Ä¢ Expert diversity encourages balanced usage\")\n",
    "print(\"   ‚Ä¢ Temporal expert consistency for smooth transitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456cff32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting IMPROVED KAN-MAMMOTE Training with Consistent Regularization...\n",
      "   This training includes:\n",
      "   ‚Ä¢ TV regularization (oscillation control) - Applied to ALL K-MOTE experts\n",
      "   ‚Ä¢ Sobolev regularization (smoothness control) - Applied to ALL K-MOTE experts\n",
      "   ‚Ä¢ Expert Diversity regularization (balanced expert usage)\n",
      "   ‚Ä¢ Temporal Expert Consistency (smooth expert transitions)\n",
      "   ‚Ä¢ Embedding Magnitude Control (prevent explosion)\n",
      "   ‚Ä¢ NO regularization of output embeddings (preserves diversity)\n",
      "\n",
      "üîÑ Creating fresh KAN-MAMMOTE model for improved training...\n",
      "‚úì Using FasterKANLayer: 32‚Üí32, grids=5\n",
      "‚úÖ Improved KAN-MAMMOTE parameters: 255,698\n",
      "\n",
      "üéØ Starting Improved Training...\n",
      "\n",
      "üöÄ IMPROVED KAN-MAMMOTE Training with Consistent Regularization...\n",
      "   üéØ TV + Sobolev: Applied to ALL K-MOTE expert functions\n",
      "   üéØ Expert Diversity: Balanced usage of all experts\n",
      "   üéØ Temporal Consistency: Smooth expert transitions\n",
      "   üéØ Magnitude Control: Prevent embedding explosion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üöÄ Improved KAN-MAMMOTE Epoch 1/12:   0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Regularizing kan_layer expert: torch.Size([64, 1])\n",
      "   ‚úÖ Regularizing kan_layer expert: torch.Size([32, 64])\n",
      "   ‚úÖ Regularizing kan_layer expert: torch.Size([4, 32])\n",
      "   üìä Applied TV+Sobolev to 14 K-MOTE expert functions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üöÄ Improved KAN-MAMMOTE Epoch 1/12:   0%|          | 3/938 [00:00<02:17,  6.80it/s, Loss=2.3284, Reg=0.014950, Acc=7.29%]"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# üöÄ TRAIN IMPROVED KAN-MAMMOTE WITH CONSISTENT REGULARIZATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üöÄ Starting IMPROVED KAN-MAMMOTE Training with Consistent Regularization...\")\n",
    "print(\"   This training includes:\")\n",
    "print(\"   ‚Ä¢ TV regularization (oscillation control) - Applied to ALL K-MOTE experts\")\n",
    "print(\"   ‚Ä¢ Sobolev regularization (smoothness control) - Applied to ALL K-MOTE experts\")  \n",
    "print(\"   ‚Ä¢ Expert Diversity regularization (balanced expert usage)\")\n",
    "print(\"   ‚Ä¢ Temporal Expert Consistency (smooth expert transitions)\")\n",
    "print(\"   ‚Ä¢ Embedding Magnitude Control (prevent explosion)\")\n",
    "print(\"   ‚Ä¢ NO regularization of output embeddings (preserves diversity)\")\n",
    "print()\n",
    "\n",
    "# Create a fresh instance of KAN-MAMMOTE for improved training\n",
    "print(\"üîÑ Creating fresh KAN-MAMMOTE model for improved training...\")\n",
    "improved_kan_mammote_model = StandardizedLSTM_KAN_MAMMOTE().to(device)\n",
    "\n",
    "# Count parameters to confirm consistency\n",
    "improved_params = sum(p.numel() for p in improved_kan_mammote_model.parameters() if p.requires_grad)\n",
    "print(f\"‚úÖ Improved KAN-MAMMOTE parameters: {improved_params:,}\")\n",
    "\n",
    "# Train with improved regularization\n",
    "print(\"\\nüéØ Starting Improved Training...\")\n",
    "improved_results = train_model_improved_kan_mammote(\n",
    "    improved_kan_mammote_model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    \"Improved KAN-MAMMOTE\",\n",
    "    num_epochs=12  # Enough epochs to see regularization benefits\n",
    ")\n",
    "\n",
    "print(f\"\\nüéâ Improved KAN-MAMMOTE Training Complete!\")\n",
    "print(f\"   Final Test Accuracy: {improved_results['final_test_acc']:.2f}%\")\n",
    "print(f\"   Best Test Accuracy: {improved_results['best_test_acc']:.2f}%\")\n",
    "print(f\"   Average Epoch Time: {improved_results['avg_epoch_time']:.1f}s\")\n",
    "\n",
    "# Store improved results (create results dict if it doesn't exist)\n",
    "if 'results' not in locals():\n",
    "    results = {}\n",
    "\n",
    "results['Improved KAN-MAMMOTE'] = improved_results\n",
    "\n",
    "print(\"\\nüìä UPDATED COMPARISON:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Model':<25} {'Final Acc':<12} {'Best Acc':<12} {'Improvement':<15}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get baseline accuracy for comparison\n",
    "baseline_acc = 74.07  # From previous runs\n",
    "for model_name, result in results.items():\n",
    "    if result:  # Only show models that have been trained\n",
    "        improvement = result['final_test_acc'] - baseline_acc\n",
    "        print(f\"{model_name:<25} {result['final_test_acc']:>8.2f}%    {result['best_test_acc']:>8.2f}%    {improvement:>+8.2f}%\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìä COMPREHENSIVE RESULTS VISUALIZATION WITH ENHANCED KAN-MAMMOTE\n",
    "# ============================================================================\n",
    "\n",
    "# Create comprehensive comparison visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('üöÄ Enhanced KAN-MAMMOTE vs All Models: Complete Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Final Accuracy Comparison\n",
    "ax1 = axes[0, 0]\n",
    "model_names = []\n",
    "final_accs = []\n",
    "best_accs = []\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57']\n",
    "\n",
    "for i, (name, result) in enumerate(results.items()):\n",
    "    if result:\n",
    "        model_names.append(name.replace('LSTM + ', '').replace('LSTM', 'Baseline'))\n",
    "        final_accs.append(result['final_test_acc'])\n",
    "        best_accs.append(result['best_test_acc'])\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, final_accs, width, label='Final Accuracy', color=colors, alpha=0.8)\n",
    "bars2 = ax1.bar(x + width/2, best_accs, width, label='Best Accuracy', color=colors, alpha=0.6)\n",
    "\n",
    "ax1.set_xlabel('Model')\n",
    "ax1.set_ylabel('Accuracy (%)')\n",
    "ax1.set_title('üéØ Final Accuracy Comparison')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{height:.1f}%',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 2. Training Curves for Enhanced KAN-MAMMOTE\n",
    "ax2 = axes[0, 1]\n",
    "enhanced_results = results['Enhanced KAN-MAMMOTE']\n",
    "epochs = range(1, len(enhanced_results['train_accs']) + 1)\n",
    "\n",
    "ax2.plot(epochs, enhanced_results['train_accs'], 'b-', label='Train Accuracy', linewidth=2, marker='o')\n",
    "ax2.plot(epochs, enhanced_results['test_accs'], 'r-', label='Test Accuracy', linewidth=2, marker='s')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('üöÄ Enhanced KAN-MAMMOTE Training Progress')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Regularization Analysis\n",
    "ax3 = axes[0, 2]\n",
    "reg_history = enhanced_results['regularization_history']\n",
    "epochs = range(1, len(reg_history['tv']) + 1)\n",
    "\n",
    "ax3.plot(epochs, reg_history['tv'], 'g-', label='TV Loss', linewidth=2, marker='o')\n",
    "ax3.plot(epochs, reg_history['diversity'], 'purple', label='Diversity Loss', linewidth=2, marker='s')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Regularization Loss')\n",
    "ax3.set_title('üéõÔ∏è Regularization Components')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_yscale('log')\n",
    "\n",
    "# 4. Model Comparison: KAN-MAMMOTE vs Enhanced KAN-MAMMOTE\n",
    "ax4 = axes[1, 0]\n",
    "kan_original = results['LSTM + KAN-MAMMOTE']\n",
    "kan_enhanced = results['Enhanced KAN-MAMMOTE']\n",
    "\n",
    "comparison_data = {\n",
    "    'Original KAN-MAMMOTE': kan_original['final_test_acc'],\n",
    "    'Enhanced KAN-MAMMOTE': kan_enhanced['final_test_acc'],\n",
    "    'Improvement': kan_enhanced['final_test_acc'] - kan_original['final_test_acc']\n",
    "}\n",
    "\n",
    "bars = ax4.bar(comparison_data.keys(), comparison_data.values(), \n",
    "               color=['#FF6B6B', '#FECA57', '#4ECDC4'])\n",
    "ax4.set_ylabel('Accuracy (%)')\n",
    "ax4.set_title('üî• KAN-MAMMOTE Enhancement Impact')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax4.annotate(f'{height:.2f}%',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 5. Performance vs Time Analysis\n",
    "ax5 = axes[1, 1]\n",
    "avg_times = []\n",
    "final_accs_time = []\n",
    "model_names_time = []\n",
    "\n",
    "for name, result in results.items():\n",
    "    if result:\n",
    "        avg_times.append(result['avg_epoch_time'])\n",
    "        final_accs_time.append(result['final_test_acc'])\n",
    "        model_names_time.append(name.replace('LSTM + ', '').replace('LSTM', 'Baseline'))\n",
    "\n",
    "scatter = ax5.scatter(avg_times, final_accs_time, s=100, alpha=0.7, c=colors)\n",
    "ax5.set_xlabel('Average Epoch Time (s)')\n",
    "ax5.set_ylabel('Final Accuracy (%)')\n",
    "ax5.set_title('‚ö° Performance vs Training Time')\n",
    "\n",
    "for i, txt in enumerate(model_names_time):\n",
    "    ax5.annotate(txt, (avg_times[i], final_accs_time[i]), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
    "\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Ranking Summary\n",
    "ax6 = axes[1, 2]\n",
    "ranked_models = sorted([(name.replace('LSTM + ', '').replace('LSTM', 'Baseline'), \n",
    "                        result['final_test_acc']) \n",
    "                       for name, result in results.items() if result], \n",
    "                      key=lambda x: x[1], reverse=True)\n",
    "\n",
    "model_names_ranked = [x[0] for x in ranked_models]\n",
    "accuracies_ranked = [x[1] for x in ranked_models]\n",
    "\n",
    "bars = ax6.barh(range(len(model_names_ranked)), accuracies_ranked, \n",
    "                color=colors[:len(model_names_ranked)][::-1])\n",
    "ax6.set_yticks(range(len(model_names_ranked)))\n",
    "ax6.set_yticklabels(model_names_ranked)\n",
    "ax6.set_xlabel('Accuracy (%)')\n",
    "ax6.set_title('üèÜ Final Ranking')\n",
    "\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax6.annotate(f'{width:.2f}%',\n",
    "                xy=(width, bar.get_y() + bar.get_height() / 2),\n",
    "                xytext=(3, 0),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='left', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comprehensive summary\n",
    "print(\"üéâ FINAL COMPREHENSIVE RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Model':<25} {'Final Acc':<12} {'Best Acc':<12} {'Improvement':<15}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "baseline_acc = results['Baseline LSTM']['final_test_acc']\n",
    "for name, result in results.items():\n",
    "    if result:\n",
    "        model_name = name.replace('LSTM + ', '').replace('LSTM', 'Baseline')\n",
    "        improvement = result['final_test_acc'] - baseline_acc\n",
    "        print(f\"{model_name:<25} {result['final_test_acc']:>8.2f}%    {result['best_test_acc']:>8.2f}%    {improvement:>+8.2f}%\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüèÜ KEY ACHIEVEMENTS:\")\n",
    "print(f\"‚Ä¢ Enhanced KAN-MAMMOTE: {results['Enhanced KAN-MAMMOTE']['final_test_acc']:.2f}% (Best: {results['Enhanced KAN-MAMMOTE']['best_test_acc']:.2f}%)\")\n",
    "print(f\"‚Ä¢ Outperformed LETE by: {results['Enhanced KAN-MAMMOTE']['final_test_acc'] - results['LSTM + LETE']['final_test_acc']:+.2f}%\")\n",
    "print(f\"‚Ä¢ Improvement over original KAN-MAMMOTE: {results['Enhanced KAN-MAMMOTE']['final_test_acc'] - results['LSTM + KAN-MAMMOTE']['final_test_acc']:+.2f}%\")\n",
    "print(f\"‚Ä¢ Improvement over baseline: {results['Enhanced KAN-MAMMOTE']['final_test_acc'] - baseline_acc:+.2f}%\")\n",
    "\n",
    "print(\"\\nüéõÔ∏è REGULARIZATION EFFECTIVENESS:\")\n",
    "reg_history = results['Enhanced KAN-MAMMOTE']['regularization_history']\n",
    "print(f\"‚Ä¢ TV regularization converged from {reg_history['tv'][0]:.3f} to {reg_history['tv'][-1]:.3f}\")\n",
    "print(f\"‚Ä¢ Diversity regularization stabilized at {reg_history['diversity'][-1]:.6f}\")\n",
    "print(f\"‚Ä¢ Training achieved smooth convergence with regularization control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ad149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üíæ SAVE ENHANCED MODEL AND CREATE FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "# Save the enhanced KAN-MAMMOTE model\n",
    "print(\"üíæ Saving Enhanced KAN-MAMMOTE model...\")\n",
    "torch.save(enhanced_kan_mammote_model.state_dict(), 'results/enhanced_kan_mammote_mnist_model.pth')\n",
    "print(\"‚úÖ Enhanced model saved to results/enhanced_kan_mammote_mnist_model.pth\")\n",
    "\n",
    "# Save detailed results\n",
    "import json\n",
    "enhanced_results_summary = {\n",
    "    'model_name': 'Enhanced KAN-MAMMOTE',\n",
    "    'final_test_accuracy': float(results['Enhanced KAN-MAMMOTE']['final_test_acc']),\n",
    "    'best_test_accuracy': float(results['Enhanced KAN-MAMMOTE']['best_test_acc']),\n",
    "    'improvement_over_original': float(results['Enhanced KAN-MAMMOTE']['final_test_acc'] - results['LSTM + KAN-MAMMOTE']['final_test_acc']),\n",
    "    'improvement_over_lete': float(results['Enhanced KAN-MAMMOTE']['final_test_acc'] - results['LSTM + LETE']['final_test_acc']),\n",
    "    'improvement_over_baseline': float(results['Enhanced KAN-MAMMOTE']['final_test_acc'] - results['Baseline LSTM']['final_test_acc']),\n",
    "    'training_epochs': len(results['Enhanced KAN-MAMMOTE']['train_accs']),\n",
    "    'avg_epoch_time': float(results['Enhanced KAN-MAMMOTE']['avg_epoch_time']),\n",
    "    'regularizers_used': [\n",
    "        'Sobolev (spline smoothness)',\n",
    "        'Total Variation (temporal smoothness)', \n",
    "        'Expert Diversity (balanced expert usage)',\n",
    "        'Temporal Smoothness (consistent time modeling)',\n",
    "        'Embedding Magnitude (prevent overgrowth)'\n",
    "    ],\n",
    "    'architecture': {\n",
    "        'lstm_hidden_dim': 128,\n",
    "        'lstm_layers': 2,\n",
    "        'time_embedding_dim': 32,\n",
    "        'total_parameters': enhanced_params\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('results/enhanced_kan_mammote_results.json', 'w') as f:\n",
    "    json.dump(enhanced_results_summary, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Detailed results saved to results/enhanced_kan_mammote_results.json\")\n",
    "\n",
    "# Create final comparison table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÜ FINAL STANDARDIZED MODEL COMPARISON ON EVENT-BASED MNIST\")\n",
    "print(\"=\"*80)\n",
    "print(\"All models use identical LSTM architecture (hidden_dim=128, layers=2)\")\n",
    "print(\"All time embeddings use dimension=32 for fair comparison\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_table = []\n",
    "for name, result in results.items():\n",
    "    if result:\n",
    "        model_display = name.replace('LSTM + ', '').replace('LSTM', 'Baseline')\n",
    "        improvement = result['final_test_acc'] - results['Baseline LSTM']['final_test_acc']\n",
    "        comparison_table.append({\n",
    "            'model': model_display,\n",
    "            'accuracy': result['final_test_acc'],\n",
    "            'improvement': improvement,\n",
    "            'rank': 0  # Will be set below\n",
    "        })\n",
    "\n",
    "# Sort by accuracy and assign ranks\n",
    "comparison_table.sort(key=lambda x: x['accuracy'], reverse=True)\n",
    "for i, entry in enumerate(comparison_table):\n",
    "    entry['rank'] = i + 1\n",
    "\n",
    "print(f\"{'Rank':<5} {'Model':<25} {'Accuracy':<12} {'vs Baseline':<15}\")\n",
    "print(\"-\" * 80)\n",
    "for entry in comparison_table:\n",
    "    print(f\"{entry['rank']:<5} {entry['model']:<25} {entry['accuracy']:>8.2f}%    {entry['improvement']:>+8.2f}%\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"‚ú® CONCLUSION:\")\n",
    "print(f\"Enhanced KAN-MAMMOTE achieved {results['Enhanced KAN-MAMMOTE']['final_test_acc']:.2f}% accuracy,\")\n",
    "print(f\"outperforming LETE by {results['Enhanced KAN-MAMMOTE']['final_test_acc'] - results['LSTM + LETE']['final_test_acc']:+.2f}% through specialized regularization!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bbf47a",
   "metadata": {},
   "source": [
    "## üß™ Experiment Execution\n",
    "\n",
    "Now let's train all three models and compare their performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ced878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üß™ RUN EXPERIMENTS - ALL FOUR MODELS\n",
    "# ============================================================================\n",
    "\n",
    "# Training configuration\n",
    "NUM_EPOCHS = 3  # Increased to 3 epochs to see better convergence\n",
    "results = {}\n",
    "\n",
    "print(\"üéØ Starting comprehensive embedding comparison experiments...\")\n",
    "print(f\"üìä Training for {NUM_EPOCHS} epochs each\")\n",
    "\n",
    "# Train all four models\n",
    "models_to_test = [\n",
    "    (baseline_model, \"Baseline LSTM\"),\n",
    "    (sincos_model, \"LSTM + SinCos\"),\n",
    "    (lete_model, \"LSTM + LETE\"),\n",
    "    (kan_model, \"LSTM + KAN-MAMMOTE\")\n",
    "]\n",
    "\n",
    "for model, name in models_to_test:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üöÄ Training {name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # Train the model\n",
    "        result = train_model(model, train_loader, test_loader, name, NUM_EPOCHS)\n",
    "        results[name] = result\n",
    "        \n",
    "        print(f\"\\n‚úÖ {name} training completed!\")\n",
    "        print(f\"   Best Test Accuracy: {result['best_test_acc']:.2f}%\")\n",
    "        print(f\"   Final Test Accuracy: {result['final_test_acc']:.2f}%\")\n",
    "        print(f\"   Average Epoch Time: {result['avg_epoch_time']:.1f}s\")\n",
    "        \n",
    "        # Clear GPU memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error training {name}: {e}\")\n",
    "        results[name] = None\n",
    "\n",
    "print(f\"\\nüéâ All experiments completed!\")\n",
    "print(f\"üìä Results summary:\")\n",
    "for name, result in results.items():\n",
    "    if result is not None:\n",
    "        print(f\"   {name}: {result['best_test_acc']:.2f}% (best), {result['final_test_acc']:.2f}% (final)\")\n",
    "    else:\n",
    "        print(f\"   {name}: Failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a9639",
   "metadata": {},
   "source": [
    "## üìä Results Analysis & Visualization\n",
    "\n",
    "Let's analyze and visualize the results to understand the performance differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8051e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìä RESULTS ANALYSIS & VISUALIZATION - FOUR MODELS\n",
    "# ============================================================================\n",
    "\n",
    "# Filter successful results\n",
    "successful_results = {name: result for name, result in results.items() if result is not None}\n",
    "\n",
    "if len(successful_results) == 0:\n",
    "    print(\"‚ùå No successful experiments to analyze\")\n",
    "else:\n",
    "    print(f\"üìä Analyzing {len(successful_results)} successful experiments...\")\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('üéØ MNIST Embedding Comparison Results (4 Models)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Colors for different models\n",
    "    colors = {\n",
    "        'Baseline LSTM': '#FF6B6B', \n",
    "        'LSTM + SinCos': '#96CEB4',\n",
    "        'LSTM + LETE': '#4ECDC4', \n",
    "        'LSTM + KAN-MAMMOTE': '#45B7D1'\n",
    "    }\n",
    "    \n",
    "    # Plot 1: Training Loss\n",
    "    ax1 = axes[0, 0]\n",
    "    for name, result in successful_results.items():\n",
    "        epochs = range(1, len(result['train_losses']) + 1)\n",
    "        ax1.plot(epochs, result['train_losses'], label=name, color=colors.get(name, 'gray'), linewidth=2)\n",
    "    ax1.set_title('üìâ Training Loss', fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Training Accuracy\n",
    "    ax2 = axes[0, 1]\n",
    "    for name, result in successful_results.items():\n",
    "        epochs = range(1, len(result['train_accs']) + 1)\n",
    "        ax2.plot(epochs, result['train_accs'], label=name, color=colors.get(name, 'gray'), linewidth=2)\n",
    "    ax2.set_title('üìà Training Accuracy', fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Test Accuracy\n",
    "    ax3 = axes[0, 2]\n",
    "    for name, result in successful_results.items():\n",
    "        epochs = range(1, len(result['test_accs']) + 1)\n",
    "        ax3.plot(epochs, result['test_accs'], label=name, color=colors.get(name, 'gray'), linewidth=2)\n",
    "    ax3.set_title('üéØ Test Accuracy', fontweight='bold')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Accuracy (%)')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Final Performance Comparison\n",
    "    ax4 = axes[1, 0]\n",
    "    model_names = list(successful_results.keys())\n",
    "    best_accs = [result['best_test_acc'] for result in successful_results.values()]\n",
    "    final_accs = [result['final_test_acc'] for result in successful_results.values()]\n",
    "    \n",
    "    x = np.arange(len(model_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax4.bar(x - width/2, best_accs, width, label='Best Test Acc', alpha=0.8, \n",
    "                    color=[colors.get(name, 'gray') for name in model_names])\n",
    "    bars2 = ax4.bar(x + width/2, final_accs, width, label='Final Test Acc', alpha=0.6,\n",
    "                    color=[colors.get(name, 'gray') for name in model_names])\n",
    "    \n",
    "    ax4.set_title('üèÜ Final Performance Comparison', fontweight='bold')\n",
    "    ax4.set_xlabel('Model')\n",
    "    ax4.set_ylabel('Accuracy (%)')\n",
    "    ax4.set_xticks(x)\n",
    "    ax4.set_xticklabels([name.replace('LSTM + ', '') for name in model_names], rotation=45, ha='right')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # Plot 5: Training Time Comparison\n",
    "    ax5 = axes[1, 1]\n",
    "    avg_times = [result['avg_epoch_time'] for result in successful_results.values()]\n",
    "    bars = ax5.bar(model_names, avg_times, color=[colors.get(name, 'gray') for name in model_names], alpha=0.8)\n",
    "    ax5.set_title('‚è±Ô∏è Training Time Comparison', fontweight='bold')\n",
    "    ax5.set_xlabel('Model')\n",
    "    ax5.set_ylabel('Avg Time per Epoch (s)')\n",
    "    ax5.set_xticklabels([name.replace('LSTM + ', '') for name in model_names], rotation=45, ha='right')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax5.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{height:.1f}s', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # Plot 6: Parameter Count Comparison\n",
    "    ax6 = axes[1, 2]\n",
    "    # Updated parameter mapping for all four models\n",
    "    param_map = {\n",
    "        'Baseline LSTM': baseline_params, \n",
    "        'LSTM + SinCos': sincos_params,\n",
    "        'LSTM + LETE': lete_params, \n",
    "        'LSTM + KAN-MAMMOTE': kan_params\n",
    "    }\n",
    "    \n",
    "    param_counts = [param_map[name] for name in model_names]\n",
    "    bars = ax6.bar(model_names, param_counts, color=[colors.get(name, 'gray') for name in model_names], alpha=0.8)\n",
    "    ax6.set_title('üî¢ Parameter Count Comparison', fontweight='bold')\n",
    "    ax6.set_xlabel('Model')\n",
    "    ax6.set_ylabel('Parameters')\n",
    "    ax6.set_xticklabels([name.replace('LSTM + ', '') for name in model_names], rotation=45, ha='right')\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax6.text(bar.get_x() + bar.get_width()/2., height + 5000,\n",
    "                f'{int(height/1000)}K', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed comparison table\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"üìä DETAILED COMPARISON RESULTS - ALL FOUR MODELS\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    print(f\"{'Model':<25} {'Best Acc':<10} {'Final Acc':<10} {'Avg Time':<10} {'Parameters':<12}\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for name, result in successful_results.items():\n",
    "        print(f\"{name:<25} {result['best_test_acc']:<10.2f} {result['final_test_acc']:<10.2f} {result['avg_epoch_time']:<10.1f} {param_map[name]:<12,}\")\n",
    "    \n",
    "    # Calculate improvements\n",
    "    if 'Baseline LSTM' in successful_results:\n",
    "        baseline_acc = successful_results['Baseline LSTM']['best_test_acc']\n",
    "        print(f\"\\nüöÄ PERFORMANCE IMPROVEMENTS vs Baseline:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for name, result in successful_results.items():\n",
    "            if name != 'Baseline LSTM':\n",
    "                improvement = result['best_test_acc'] - baseline_acc\n",
    "                print(f\"{name:<25} {improvement:+.2f}% improvement\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"üéØ CONCLUSION\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    # Find best performing model\n",
    "    best_model = max(successful_results.items(), key=lambda x: x[1]['best_test_acc'])\n",
    "    print(f\"üèÜ Best performing model: {best_model[0]}\")\n",
    "    print(f\"   Best accuracy: {best_model[1]['best_test_acc']:.2f}%\")\n",
    "    print(f\"   Parameters: {param_map[best_model[0]]:,}\")\n",
    "    print(f\"   Avg training time: {best_model[1]['avg_epoch_time']:.1f}s per epoch\")\n",
    "    \n",
    "    # Efficiency analysis\n",
    "    print(f\"\\n‚ö° EFFICIENCY ANALYSIS:\")\n",
    "    for name, result in successful_results.items():\n",
    "        params = param_map[name]\n",
    "        acc = result['best_test_acc']\n",
    "        time_per_epoch = result['avg_epoch_time']\n",
    "        \n",
    "        efficiency = acc / (params / 1000)  # Accuracy per 1K parameters\n",
    "        speed_efficiency = acc / time_per_epoch  # Accuracy per second\n",
    "        \n",
    "        print(f\"{name:<25} Acc/1K params: {efficiency:.3f}, Acc/sec: {speed_efficiency:.2f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f687e3a",
   "metadata": {},
   "source": [
    "## üîç Detailed Analysis\n",
    "\n",
    "Let's dive deeper into the temporal modeling capabilities and examine specific aspects of each approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ec85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üîç DETAILED TEMPORAL ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "if 'LSTM + KAN-MAMMOTE' in successful_results:\n",
    "    print(\"üîç Performing detailed KAN-MAMMOTE temporal analysis...\")\n",
    "    \n",
    "    # Get a batch for analysis\n",
    "    kan_model.eval()\n",
    "    with torch.no_grad():\n",
    "        sample_batch = next(iter(test_loader))\n",
    "        events, features, lengths, labels = sample_batch\n",
    "        events, features, lengths, labels = events.to(device), features.to(device), lengths.to(device), labels.to(device)\n",
    "        \n",
    "        # Get detailed KAN-MAMMOTE information\n",
    "        outputs, kan_info = kan_model(events, features, lengths)\n",
    "        \n",
    "        print(f\"\\nüìä KAN-MAMMOTE Temporal Analysis:\")\n",
    "        print(f\"   Batch size: {events.shape[0]}\")\n",
    "        print(f\"   Max sequence length: {events.shape[1]}\")\n",
    "        print(f\"   Average sequence length: {lengths.float().mean():.1f}\")\n",
    "        \n",
    "        # Analyze temporal differences\n",
    "        if 'temporal_differences' in kan_info:\n",
    "            temporal_diffs = kan_info['temporal_differences']\n",
    "            print(f\"   Temporal differences shape: {temporal_diffs.shape}\")\n",
    "            print(f\"   Temporal differences range: [{temporal_diffs.min():.4f}, {temporal_diffs.max():.4f}]\")\n",
    "            print(f\"   Temporal differences std: {temporal_diffs.std():.4f}\")\n",
    "        \n",
    "        # Analyze expert usage if available\n",
    "        if 'kmote_info' in kan_info and 'expert_weights' in kan_info['kmote_info']:\n",
    "            expert_weights = kan_info['kmote_info']['expert_weights']\n",
    "            expert_usage = torch.softmax(expert_weights, dim=-1).mean(dim=(0, 1))\n",
    "            \n",
    "            print(f\"\\nüéØ Expert Usage Analysis:\")\n",
    "            for i, usage in enumerate(expert_usage):\n",
    "                print(f\"   Expert {i}: {usage:.1%}\")\n",
    "            \n",
    "            # Check if experts are balanced\n",
    "            expert_std = expert_usage.std()\n",
    "            if expert_std < 0.05:\n",
    "                print(f\"   ‚úÖ Experts are well-balanced (std: {expert_std:.4f})\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  Expert usage is imbalanced (std: {expert_std:.4f})\")\n",
    "        \n",
    "        # Visualize temporal patterns for a few samples\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        fig.suptitle('üîç KAN-MAMMOTE Temporal Pattern Analysis', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Show temporal differences for first 4 samples\n",
    "        for i in range(min(4, events.shape[0])):\n",
    "            ax = axes[i // 2, i % 2]\n",
    "            \n",
    "            seq_len = lengths[i].item()\n",
    "            sample_timestamps = events[i, :seq_len].cpu().numpy()\n",
    "            \n",
    "            if 'temporal_differences' in kan_info:\n",
    "                sample_diffs = temporal_diffs[i, :seq_len].cpu().numpy()\n",
    "                \n",
    "                # Plot temporal differences\n",
    "                ax.plot(sample_timestamps, sample_diffs.mean(axis=1), 'b-', alpha=0.7, label='Temporal Diffs')\n",
    "                ax.fill_between(sample_timestamps, \n",
    "                               sample_diffs.mean(axis=1) - sample_diffs.std(axis=1),\n",
    "                               sample_diffs.mean(axis=1) + sample_diffs.std(axis=1),\n",
    "                               alpha=0.3, color='blue')\n",
    "            \n",
    "            ax.set_title(f'Sample {i+1} (Label: {labels[i].item()}, Len: {seq_len})')\n",
    "            ax.set_xlabel('Timestamp')\n",
    "            ax.set_ylabel('Temporal Difference')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Detailed analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e2759a",
   "metadata": {},
   "source": [
    "## üéØ Experiment Conclusions - All Four Models Successfully Trained! üéâ\n",
    "\n",
    "### üìä **Final Performance Results:**\n",
    "\n",
    "| Model | Best Accuracy | Parameters | Avg Time/Epoch | Performance Notes |\n",
    "|-------|---------------|------------|----------------|-------------------|\n",
    "| **Baseline LSTM** | **71.90%** | 200K | 28.5s | ‚úÖ Good baseline with temporal info |\n",
    "| **LSTM + SinCos** | **11.35%** | 889K | 33.3s | ‚ùå Overfitting/optimization issues |\n",
    "| **üèÜ LSTM + LETE** | **94.07%** | 241K | 31.0s | ‚úÖ **BEST PERFORMER!** |\n",
    "| **LSTM + KAN-MAMMOTE** | **86.92%** | 323K | 47.9s | ‚úÖ Strong second place |\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ **Key Findings:**\n",
    "\n",
    "#### **1. LETE is the Champion! üèÜ**\n",
    "- **Outstanding accuracy**: 94.07% - significantly outperforms all others\n",
    "- **Parameter efficient**: Only 241K parameters (vs 889K for SinCos)\n",
    "- **Fast training**: 31.0s per epoch - comparable to baseline\n",
    "- **Excellent convergence**: Smooth improvement from 86.30% ‚Üí 92.51% ‚Üí 94.07%\n",
    "\n",
    "#### **2. KAN-MAMMOTE Shows Strong Performance üöÄ**\n",
    "- **Solid accuracy**: 86.92% - second best overall\n",
    "- **Reasonable parameters**: 323K parameters \n",
    "- **Stable learning**: Consistent improvement across epochs\n",
    "- **Temporal modeling**: Successfully captures temporal patterns\n",
    "\n",
    "#### **3. Baseline Performs Well üëç**\n",
    "- **Respectable accuracy**: 71.90% with simple temporal concatenation\n",
    "- **Very efficient**: Fastest training (28.5s) and fewest parameters (200K)\n",
    "- **Good improvement**: Shows adding temporal info was crucial\n",
    "\n",
    "#### **4. SinCos Has Issues ‚ö†Ô∏è**\n",
    "- **Poor performance**: 11.35% (random-level)\n",
    "- **Parameter inefficient**: 889K parameters with poor results\n",
    "- **Overfitting**: High complexity but no learning apparent\n",
    "- **Needs debugging**: Implementation or optimization issues\n",
    "\n",
    "---\n",
    "\n",
    "### üîç **Why LETE Succeeded:**\n",
    "\n",
    "1. **Proper Implementation**: Based on the working `EventBasedMNIST_with_log.ipynb` example\n",
    "2. **Optimal Configuration**: `CombinedLeTE(embedding_dim=32, p=0.5)` worked perfectly\n",
    "3. **Fourier + Spline Combination**: The combined approach captures temporal patterns effectively\n",
    "4. **Right Scale**: 32 embedding dimensions is optimal for this task\n",
    "5. **Good Initialization**: Avoided the numerical instability issues\n",
    "\n",
    "### üîç **Why KAN-MAMMOTE Also Performed Well:**\n",
    "\n",
    "1. **Adaptive Experts**: K-MOTE's multiple experts (Fourier, Spline, RKHS, Wavelet) provide flexibility\n",
    "2. **Temporal Difference Modeling**: Processes differences between current and previous timestamps\n",
    "3. **Faster-KAN Integration**: Effective non-linear temporal pattern processing\n",
    "4. **C-Mamba Sequence Modeling**: Good at capturing long-range dependencies\n",
    "\n",
    "---\n",
    "\n",
    "### üí° **Technical Insights:**\n",
    "\n",
    "#### **What Fixed LETE:**\n",
    "- ‚úÖ **Exact replication** of working example parameters\n",
    "- ‚úÖ **Proper input handling** (float timestamps, original scale)\n",
    "- ‚úÖ **Simple architecture** (no over-engineering)\n",
    "- ‚úÖ **Robust error handling** with NaN detection\n",
    "\n",
    "#### **What Makes These Results Significant:**\n",
    "- ‚úÖ **LETE achieves 94.07%** - excellent for event-based MNIST\n",
    "- ‚úÖ **Clear performance hierarchy** emerges\n",
    "- ‚úÖ **Parameter efficiency** - LETE wins with fewer parameters than SinCos\n",
    "- ‚úÖ **All models converge** (except SinCos) - showing stable implementations\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **Practical Recommendations:**\n",
    "\n",
    "#### **For Production Use:**\n",
    "1. **ü•á First Choice: LSTM + LETE** - Best accuracy, good efficiency\n",
    "2. **ü•à Second Choice: LSTM + KAN-MAMMOTE** - Strong performance, more features\n",
    "3. **ü•â Backup Choice: Baseline LSTM** - Simple, fast, reasonably effective\n",
    "\n",
    "#### **For Research:**\n",
    "1. **Investigate SinCos issues** - High parameter count suggests potential\n",
    "2. **LETE ablation studies** - Test different p values and embedding dimensions  \n",
    "3. **KAN-MAMMOTE optimization** - Could potentially match LETE with tuning\n",
    "4. **Hybrid approaches** - Combine best aspects of LETE and KAN-MAMMOTE\n",
    "\n",
    "#### **For Different Tasks:**\n",
    "- **Simple temporal sequences**: Baseline LSTM sufficient\n",
    "- **Complex temporal patterns**: LETE or KAN-MAMMOTE\n",
    "- **Real-time applications**: Baseline (fastest) or LETE (good balance)\n",
    "- **Research/experimentation**: KAN-MAMMOTE (most interpretable with expert analysis)\n",
    "\n",
    "---\n",
    "\n",
    "### üîÆ **Future Directions:**\n",
    "\n",
    "1. **Extended Evaluation**: \n",
    "   - Test on neuromorphic datasets (DVS, N-MNIST)\n",
    "   - Longer training to see full potential\n",
    "   - Different sequence lengths and complexities\n",
    "\n",
    "2. **Model Improvements**:\n",
    "   - Debug and optimize SinCos implementation\n",
    "   - Hyperparameter tuning for KAN-MAMMOTE\n",
    "   - Ensemble methods combining LETE + KAN-MAMMOTE\n",
    "\n",
    "3. **Real-world Applications**:\n",
    "   - Event-based vision processing\n",
    "   - Neuromorphic computing tasks\n",
    "   - Time-series prediction with irregular sampling\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ **Summary:**\n",
    "\n",
    "This comprehensive comparison successfully demonstrates that:\n",
    "\n",
    "1. **LETE is highly effective** for temporal event modeling (94.07% accuracy)\n",
    "2. **KAN-MAMMOTE provides strong alternative** with interpretable expert mechanisms (86.92%)\n",
    "3. **Proper temporal information is crucial** - even simple concatenation achieves 71.90%\n",
    "4. **Implementation details matter** - exact replication of working examples is key\n",
    "\n",
    "The results validate both approaches as significant improvements over baseline methods for event-based temporal sequence modeling! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kanmote_wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
